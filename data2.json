[
  {
    "question": "以下哪些情况可能导致大模型检索不准确？",
    "options": [
      "A. 文档中包含大量的图片信息，而当前的文档解析器无法有效提取和理解图片内容。",
      "B. 使用了基于深度学习的语义搜索引擎，但模型训练数据不足，导致检索结果不准确。",
      "C. 文档中包含复杂的表格结构，而简单的文本解析器无法理解表格单元格之间的关系。",
      "D. 使用了复杂的文档解析器，导致解析速度慢，影响检索效率。",
      "E. 索引构建过程中使用了错误的 embedding 模型，导致语义相似度计算错误。",
      "F. 文档切片时，仅简单地按照字符长度进行分割，丢失了文档的语义信息。"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "E",
      "F"
    ],
    "analysis": "复杂文档解析器导致解析速度慢，主要影响的是检索效率，而非检索的准确性。",
    "type": "多选题",
    "id": "554"
  },
  {
    "question": "关于 Qwen-Max、CosyVoice 和 moviepy 的协同使用，以下哪些说法是正确的？",
    "options": [
      "A. CosyVoice 可以将文本转换为音频。",
      "B. CosyVoice 的主要功能是视频剪辑。",
      "C. moviepy 可以直接将文本转换为视频。",
      "D. Qwen-Max 主要用于生成视频字幕。",
      "E. moviepy 可以用来获取音频文件的持续时间，用于生成字幕。",
      "F. 使用这三个工具的典型流程是，Qwen-Max -> CosyVoice -> moviepy。"
    ],
    "answer": [
      "A",
      "E",
      "F"
    ],
    "analysis": "B.CosyVoice 主要功能是语音合成，将文本转化为语音，而不是视频剪辑;C.moviepy 是\n一个用于视频编辑的 Python 库，但它不能直接将文本转换为视频，需要结合其他操作来实\n现;D.Qwen - Max 是一个语言模型，主要用于生成文本等自然语言处理任务，而不是专门用于\n生成视频字幕，虽然可以生成字幕相关文本，但这不是其主要功能.",
    "type": "多选题",
    "id": "555"
  },
  {
    "question": "小李正在使用阿里云百炼大模型服务平台开发一款 AI 语音助手 APP。为了确保 APP 能够\n顺利上线，小李在开发过程中应注意哪些事项？",
    "options": [
      "A. 关注《生成式人工智能服务管理暂行办法》的最新动态，及时调整 APP 的功能和策略。",
      "B. 在 APP 上线前完成算法备案手续。",
      "C. 忽略备案要求，尽快上线抢占市场。",
      "D. 对用户生成的 AIGC 内容进行审核和过滤，避免传播违规信息。",
      "E. 收集用户数据前需获得用户明确同意，并保障用户数据安全。",
      "F. 在 APP 中明确告知用户该应用使用了 AIGC 技术。"
    ],
    "answer": [
      "A",
      "B",
      "D",
      "E",
      "F"
    ],
    "analysis": "c 严重错误。未备案即上线属于违法行为，将面临处罚",
    "type": "多选题",
    "id": "556"
  },
  {
    "question": "以下哪些因素会影响 RAG 系统的性能？",
    "options": [
      "A. 硬件资源的限制",
      "B. 文档的质量和数量",
      "C. 向量数据库的类型和配置",
      "D. 查询语句的表达方式",
      "E. 所使用的预训练语言模型的大小和性能",
      "F. 切片方法的选择"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D",
      "E",
      "F"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "557"
  },
  {
    "question": "通过 Llamaindex 创建 RAG 应用，这段代码有哪些问题？\npython\nquery_engine = index.as_query_engine(\nsimilarity_top_k=3,\nstreaming=True,\nnode_postprocessors=[\nDepthScopeRank(top_n=8, model=\"gte-rerank\"),\nSimilarityPostprocessor(similarity_cutoff=1)]\n)\nresponse = query_engine.retrieve(\"需求分析使用的工具是什么？\")\nresponse.print_response_stream()",
    "options": [
      "A. query_engine 不支持 retrieve",
      "B. 重排选中的 chunk 数大于初步召回的 chunk 数",
      "C. 相似度阈值设置过高",
      "D. Llamaindex在 RAG 回答时不可以使用流式输出"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "558"
  },
  {
    "question": "以下哪些描述符合基于语义的文档切片的理念？",
    "options": [
      "A. 使用机器学习模型对文档进行语义分析，并根据语义边界进行切分。",
      "B. 在 Chunk 中添加上下文信息，例如标题、父级列表项等。",
      "C. 将代码模块单独切出来，并标注其编程语言。",
      "D. 将文档按照固定长度进行切分。",
      "E. 将表格的每个单元格作为一个独立的 Chunk。",
      "F. 根据文档的结构，例如标题、段落、列表等进行切分"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "F"
    ],
    "analysis": "C 固定长度切片（如 512字符）是机械式方法，会破坏句子、段落或逻辑单元的完整性，\n违背语义切片理念。D 将完整表格（或逻辑子表）作为一个 Chunk，或转换为 Markdown等保留\n结构的格式",
    "type": "多选题",
    "id": "559"
  },
  {
    "question": "下列关于将 AgentModule 类设计为基类的原因，正确的有哪些？\npython\nclass AgentModule():\ndef __init__(self, name: str, description: str):\nself.name = name\nself.description = description\ndef __call__(self, query:str):\nreturn self.query(query)\ndef query(self, query:str):\npass",
    "options": [
      "A. 简化子类中的构造函数，减少重复代码",
      "B. 由于 Python 不支持多重继承，因此需要这样设计",
      "C. 允许每个子类定义自己的 query 方法，增加灵活性",
      "D. 作为一个基类，可以方便地隐藏私有属性，保护数据",
      "E. 提供统一的 call 方法以便通过相同的方式调用所有子类",
      "F. 使得多个不同的代理模块可以共享相同的接口，实现代码复用"
    ],
    "answer": [
      "A",
      "C",
      "E",
      "F"
    ],
    "analysis": "B Python 支持多重继承，因此该选项的说法本身错误，设计基类与 Python 是否支持多\n重继承无关;D 基类的设计主要是为了实现代码复用和统一接口，而不是为了隐藏私有属\n性,Python 中通过命名约定来表示私有属性，与基类的设计并无直接关系",
    "type": "多选题",
    "id": "560"
  },
  {
    "question": "关于大模型在文本处理中的局限性，以下哪些陈述是准确的？",
    "options": [
      "A. 即使有合适的系统提示词，大模型生成的内容仍需人工复审以保证质量。",
      "B. 大模型技术已经完全成熟，能够无差错地执行所有文本转换和润色任务。",
      "C. 大模型可能在处理特定领域专业术语时出现误解。",
      "D. 大模型对用户查询的依赖性强，如果查询表述不清，结果可能偏离预期。",
      "E. 在没有明确指示的情况下，大模型可能无法自动识别源语言和目标语言。"
    ],
    "answer": [
      "A",
      "C",
      "D",
      "E"
    ],
    "analysis": "大模型技术还在不断发展和完善中，存在局限性，不能无差错地执行所有文本转换和润\n色任务",
    "type": "多选题",
    "id": "561"
  },
  {
    "question": "在使用大语言模型时，什么是 “样例” 的作用？",
    "options": [
      "A. 确定目标用户",
      "B. 辅助模型生成单一答案",
      "C. 明确限制模型的回答长度",
      "D. 提供有指导性的案例",
      "E. 设定模型的情感色彩",
      "F. 抽象出实现方案"
    ],
    "answer": [
      "B",
      "D",
      "E"
    ],
    "analysis": "A 用户分析、C 长度控制、F抽象方案",
    "type": "多选题",
    "id": "562"
  },
  {
    "question": "在下面的代码片段中，哪些是微调大语言模型训练循环中必要的步骤？",
    "options": [
      "A. model.train ()",
      "B. loss = criterion (predictions, targets)",
      "C. predictions = model (inputs)",
      "D. optimizer.step ()",
      "E. optimizer.zero_grad ()",
      "F. loss.backward ()"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D",
      "E",
      "F"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "563"
  },
  {
    "question": "下列哪些因素会影响大语言模型微调的效果？",
    "options": [
      "A. 是否采用数据增强技术",
      "B. 计算资源的限制",
      "C. 微调数据的质量和数量",
      "D. 预训练模型的选择",
      "E. 微调持续的轮数（epochs）",
      "F. 微调时使用的超参数设置"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D",
      "E",
      "F"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "564"
  },
  {
    "question": "用户上传了一个包含复杂表格的 Markdown 文档，使用默认的 RAG 流程进行问答。用户提\n问关于表格中特定单元格含义的问题时，大模型经常给出错误或不相关的答案。请问以下哪些\n方案可以尝试解决这个问题？",
    "options": [
      "A. 对用户提问进行预处理，提取表格相关的关键词。",
      "B. 在文档切片时，将表格的行列信息添加到每个单元格的 Chunk 中。",
      "C. 将表格转换成 JSON 格式，然后使用 JSON Loader 加载数据。",
      "D. 使用 OCR 技术识别表格中的文字，并将识别结果添加到文本中。",
      "E. 使用更强大的 Embedding 模型。",
      "F. 增加训练数据，让大模型更好地理解表格内容。"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "E"
    ],
    "analysis": "C 方案最彻底，B+A组合适用于快速改进，E 方案作为补充，D/F不建议",
    "type": "多选题",
    "id": "565"
  },
  {
    "question": "下列代码片段中，哪些涉及模型训练过程中的正则化或优化策略？",
    "options": [
      "A. weight_decay = 0.001",
      "B. ACP大模型-1.png",
      "C. optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)",
      "D. scheduler = StepLR(optimizer, step_size=10, gamma=0.1)",
      "E. model = nn.Dropout(p=0.2)",
      "F. criterion = nn.CrossEntropyLoss()"
    ],
    "answer": [
      "A",
      "C",
      "D",
      "E"
    ],
    "analysis": "B/F为损失计算，A/E 属正则化，C/D属优化策略",
    "type": "多选题",
    "id": "566"
  },
  {
    "question": "通过 LlamaIndex 创建 RAG 应用，在修改默认 prompt 时，包含以下哪些步骤？",
    "options": [
      "A. 定义新的 prompt 字符串，将 chunk 和 query 的位置空出来",
      "B. 使用新的 prompt 初始化一个 PromptTemplate 对象",
      "C. 对新的 prompt 进行保存，使得 LlamaIndex 中的源代码 prompt 也变成中文",
      "D. 用 index 的 update_prompts 方法将新的 prompt 同步上去"
    ],
    "answer": [
      "A",
      "B"
    ],
    "analysis": "C 和 D 选项存在事实性错误",
    "type": "多选题",
    "id": "567"
  },
  {
    "question": "有关输出格式要素的描述，以下哪项是正确的？",
    "options": [
      "A. 输出格式不影响大模型的应答",
      "B. 不需要明确不期望输出的内容",
      "C. 可使用案例来提示大模型的输出",
      "D. 应明确指出枚举值的范围",
      "E. 明确提供要输出的内容类型",
      "F. 无需结合样例来明确输出格式"
    ],
    "answer": [
      "C",
      "D",
      "E"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "568"
  },
  {
    "question": "以下哪些选项是把 DASHSCOPE_API_KEY 配置为环境变量的原因？",
    "options": [
      "A. 防止 KEY 泄漏",
      "B. 配置为环境变量可以减少代码的行数。",
      "C. 环境变量会自动被 SDK 读取和使用。",
      "D. 环境变量可以加快程序的运行速度。"
    ],
    "answer": [
      "A",
      "C"
    ],
    "analysis": "B 配置环境变量本身不会减少代码行数，而是通过 SDK 自动读取环境变量来简化认证流\n程，与代码行数无关；D 环境变量的读取属于系统级操作，对程序运行速度的影响可忽略不计，\n不会显著提升性能",
    "type": "多选题",
    "id": "569"
  },
  {
    "question": "在进行 RAGAS 评测时，使用通过自定义 API 封装的 langchain LLM 对象主要有哪些优\n点？",
    "options": [
      "A. 可以在 API 中定义 langchain LLM 类中不支持指定的参数",
      "B. 由于 langchain 官方封装好的模型有限，因此通过自定义方法选择更多模型",
      "C. 可以打印出中间结果，帮助评测人员了解分数来源",
      "D. 无需输入 API Key 即可使用大模型"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "D 选项违反 API调用基本原则，A/B/C 是自定义封装的核心价值",
    "type": "多选题",
    "id": "570"
  },
  {
    "question": "以下哪些代码片段可以用于检测用户输入中是否包含敏感词？",
    "options": [
      "A. python def detect_sensitive_words(text, sensitive_words): for word in text.split(): if word in sensitive_words: return True return False",
      "B. python def detect_sensitive_words(text, sensitive_words): return any(word in text for word in sensitive_words)",
      "C. python def detect_sensitive_words(text, sensitive_words): # added error handling try: return any(word in text.lower() for word in [w.lower() for w in sensitive_words]) except AttributeError: # in case text is not a string return False",
      "D. python import nltk def detect_sensitive_words(text, sensitive_words): tokens = nltk.word_tokenize(text) return any(token in sensitive_words for token in tokens)",
      "E. python def detect_sensitive_words(text, sensitive_words): return text in sensitive_words"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D"
    ],
    "analysis": "E 排除，其余选项均能实现基本的敏感词检测功能，尽管各有局限性",
    "type": "多选题",
    "id": "571"
  },
  {
    "question": "以下哪些选项属于提示词要素中的样例（Sample）？",
    "options": [
      "A. 请你扮演一位医生。",
      "B. 输入：汽车，输出：交通工具",
      "C. 用户输入：“我想了解一下人工智能。” 你的回复：“人工智能是……”",
      "D. 请用表格形式展示结果。",
      "E. 输入：苹果，输出：水果",
      "F. 请你总结这篇文章的中心思想 。"
    ],
    "answer": [
      "B",
      "C",
      "E"
    ],
    "analysis": "样例是指在提示词中提供具体的输入输出示例，用于指导模型生成符合期望的格式或内\n容",
    "type": "多选题",
    "id": "572"
  },
  {
    "question": "Assistant API 的 Assistant 类的各项功能中涵盖了以下哪些操作？",
    "options": [
      "A. 列举",
      "B. 剪切",
      "C. 复制",
      "D. 删除",
      "E. 更新",
      "F. 创建"
    ],
    "answer": [
      "A",
      "D",
      "E",
      "F"
    ],
    "analysis": "B/C不属于原生功能，A/D/E/F 是标准 CRUD操作",
    "type": "多选题",
    "id": "573"
  },
  {
    "question": "APIAssistantAgent 示例代码 query 函数中，哪些步骤与大语言模型交互？\npython\ndef query(self, query:str):\n\"\"\"\nquery: string, the query string to the assistant, e.g. Who is the Jack Chou?\n\"\"\"\nmessage = dashscope.Messages.create(self.thread_id, content=query)\nmessage_run = dashscope.Runs.create(self.thread_id, assistant_id=self.assistant_id)\nrun_status = dashscope.Runs.wait(message_run.id, thread_id=self.thread_id)\nif run_status.required_action:\nself.forward_and_submit_outputs(run_status)\nrun_status = dashscope.Runs.wait(run_status.id, thread_id=self.thread_id)\nmsgs = dashscope.Messages.list(self.thread_id)\nanswer = json.loads(json.dumps(msgs, default=lambda o:\no.__dict__))[\"data\"][0][\"content\"][0][\"text\"][\"value\"]\nreturn answer",
    "options": [
      "A. 调用 forward_and_submit_outputs 函数",
      "B. 调用 dashscope.Runs.wait 函数",
      "C. 创建 message 对象",
      "D. 调用 dashscope.Messages.list 函数",
      "E. 解析 msgs 获取最终答案",
      "F. 调用 dashscope.Runs.create 函数"
    ],
    "answer": [
      "B",
      "C",
      "D",
      "F"
    ],
    "analysis": "A/E属于后续处理，B/C/D/F构成完整交互链",
    "type": "多选题",
    "id": "574"
  },
  {
    "question": "以下哪些 Python 库可以用于处理视频或图像？",
    "options": [
      "A. numpy",
      "B. OpenCV",
      "C. pandas",
      "D. TensorFlow",
      "E. requests",
      "F. moviepy"
    ],
    "answer": [
      "A",
      "B",
      "D",
      "F"
    ],
    "analysis": "A 作为基础支持库入选，B/D/F 是专业多媒体库，C/E无关",
    "type": "多选题",
    "id": "575"
  },
  {
    "question": "小明开发了一款基于通义千问的 AI 写作助手小程序，计划在微信小程序平台上线。目前\n小程序已经开发完成，但尚未提交任何合规备案申请。根据相关规定，小明应该如何操作？",
    "options": [
      "A. 直接上线，后续再补充备案材料。",
      "B. 向应用商店提交应用，等待审核通过后再备案。",
      "C. 下架小程序，停止运营。",
      "D. 联系阿里云百炼大模型服务平台，咨询备案流程并按要求提交申请。",
      "E. 无需备案，直接上线即可。",
      "F. 先进行算法备案，获得备案号后再上线。"
    ],
    "answer": [
      "D",
      "F"
    ],
    "analysis": "必须完成算法备案和平台合规流程",
    "type": "多选题",
    "id": "576"
  },
  {
    "question": "以下哪些选项属于提示词要素中的 “输出格式（Output Format）”？",
    "options": [
      "A. 请你总结一下这篇文章的主要内容。",
      "B. 请用表格形式展示结果。",
      "C. 假设你是一个资深律师。",
      "D. 请使用 JSON 格式输出。",
      "E. 我希望你以第一人称的口吻写作。",
      "F. 结果需要包含姓名、年龄和地址。"
    ],
    "answer": [
      "B",
      "D",
      "F"
    ],
    "analysis": "A/C/E 属于其他提示词要素，B/D/F 是标准的输出格式指令",
    "type": "多选题",
    "id": "577"
  },
  {
    "question": "为了将 RAGAS 评测适配到中文问答场景，有哪些有效方法？",
    "options": [
      "A. 使用中文能力较强的大模型",
      "B. 将 RAGAS 自带的 prompt 翻译为中文再传入",
      "C. 在 faithfulness 中修改 json.dumps 函数，使其返回中文而非 unicode 码",
      "D. 在 System prompt 中提醒大模型：你要适配到中文问答场景"
    ],
    "answer": [
      "A",
      "B",
      "D"
    ],
    "analysis": "C 选项属于技术误用，A/B/D 构成完整的中文适配方案",
    "type": "多选题",
    "id": "578"
  },
  {
    "question": "以下关于 CosyVoice 的描述，哪些是正确的？",
    "options": [
      "A. CosyVoice 是一个文本转语音模型。",
      "B. CosyVoice 可以直接生成视频。",
      "C. CosyVoice 支持实时流式语音合成。",
      "D. CosyVoice 可以用于语音识别。"
    ],
    "answer": [
      "A",
      "C"
    ],
    "analysis": "CosyVoice 的核心能力是文本转语音（TTS）及流式合成",
    "type": "多选题",
    "id": "579"
  },
  {
    "question": "在 RAGAS 评测中，embedding模型的作用有哪些?",
    "options": [
      "A. 评估 answer 与 ground_truth 的相似度，从而计算 answer_correctness",
      "B. 评估每个 chunk 之间的相似度、从而剔除离群点",
      "C. 评估 context 与 answer 的相似度，从而计算 faithfulness",
      "D. 评估 answer 与 query 的相似度，从而计算 answer_relevancy"
    ],
    "answer": [
      "A",
      "C",
      "D"
    ],
    "analysis": "Embedding 模型直接参与 ACD 三个指标的计算，B 属于前置数据处理流程",
    "type": "多选题",
    "id": "580"
  },
  {
    "question": "通过 LlamaIndex 创建 RAG 应用，关于下面这段代码作用的描述正确的有哪些？\npython\ndef get_documents(path):\ndocuments = SimpleDirectoryReader(path).load_data()\ndocument = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\nreplacements = {\n'，': ',',\n'！': '!',\n'？': '?'\n}\nfor src, dst in replacements.items():\ndocument.text = document.text.replace(src, dst)\nreturn document",
    "options": [
      "A. 将所有 Document 对象合并为一个 Document 对象",
      "B. 对乱码内容进行数据清洗",
      "C. 将中文的标点符号预先转化为英文标点符号，使得切分时不会使得 chunk 长度过长",
      "D. 将指定文件夹中的文件加载为 document 对象"
    ],
    "answer": [
      "A",
      "C",
      "D"
    ],
    "analysis": "码仅替换特定标点符号，未涉及乱码检测或修复",
    "type": "多选题",
    "id": "581"
  },
  {
    "question": "在大语言模型微调的训练循环中，哪些步骤是必须包含的？",
    "options": [
      "A. 梯度裁剪",
      "B. 模型保存",
      "C. 正向传播",
      "D. 反向传播",
      "E. 超参数调整",
      "F. 梯度更新"
    ],
    "answer": [
      "C",
      "D",
      "F"
    ],
    "analysis": "ABE属于增强或辅助操作，非训练循环最小必需步骤",
    "type": "多选题",
    "id": "582"
  },
  {
    "question": "视频合规检测的关键步骤包括下列哪些选项？",
    "options": [
      "A. 视频上传后的用户评论分析",
      "B. 视频预处理，例如视频分段和帧提取",
      "C. 音频合规检测",
      "D. 视频编码格式的选择",
      "E. 图片合规检测",
      "F. 文本合规检测（包括字幕和音频转录文本）",
      "D.  属于视频上传前的技术处理，与内容合规性无直接关联。"
    ],
    "answer": [
      "B",
      "C",
      "E",
      "F"
    ],
    "analysis": "A. 通常属于用户生成内容审核范畴，而非视频本身的合规检测步骤。",
    "type": "多选题",
    "id": "583"
  },
  {
    "question": "下哪种做法不能 “保证关键数据的语义独立性与完整性”？",
    "options": [
      "A. 对不同的数据类型（例如文本、表格、图片）采用不同的处理方式。",
      "B. 将标题下的所有文本合并成一个段落。",
      "C. 针对表格中每一行单元格的数据，扩写加上各级标题、表格头部的字段说明",
      "D. 确保每个语义单元都有清晰的边界和完整的上下文信息。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "独立性：数据单元（如文本段落、表格行、图片标题等）应保持自身明确的语义边界，\n不与其他内容混淆。完整性：数据单元应包含足够的上下文信息，确保其含义清晰且不被割裂。",
    "type": "单选题",
    "id": "584"
  },
  {
    "question": "下列哪项不是向量数据库的主要作用？",
    "options": [
      "A. 检索向量数据",
      "B. 为向量数据构建索引",
      "C. 训练 Embedding 模型",
      "D. 存储向量数据"
    ],
    "answer": [
      "C"
    ],
    "analysis": "向量数据库用于管理已生成的向量数据，而非训练生成这些向量的模型",
    "type": "单选题",
    "id": "585"
  },
  {
    "question": "句子窗口检索的优势在于：",
    "options": [
      "A. 提高检索阶段的精确性同时，保证了生成阶段的信息完整性",
      "B. 对大模型的注意力机制进行了针对性改善",
      "C. 提高大模型生成的速度",
      "D. 可以降低对数据库存储空间要求"
    ],
    "answer": [
      "A"
    ],
    "analysis": "句子窗口检索的核心优势是通过精准检索（句子级）和上下文扩展（窗口级）平衡检索\n精度与生成质量，其他选项均不符合其设计目标。",
    "type": "单选题",
    "id": "586"
  },
  {
    "question": "在模型训练循环中，哪段代码用于更新模型权重（梯度更新）？",
    "options": [
      "A. loss = criterion(outputs, labels)",
      "B. optimizer.step()",
      "C. model.train()",
      "D. loss.backward()"
    ],
    "answer": [
      "B"
    ],
    "analysis": "前向计算（outputs = model(inputs)）→,计算损失（loss = criterion(...)）→\n反向传播（loss.backward()）→,梯度更新（optimizer.step()",
    "type": "单选题",
    "id": "587"
  },
  {
    "question": "在基于深度学习的语义搜索引擎中，embedding 模型的作用是什么？",
    "options": [
      "A. 对用户查询进行分词",
      "B. 将文本转换为向量，以便进行语义相似度计算",
      "C. 对检索结果进行排序",
      "D. 存储索引数据"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Embedding 模型负责将高维稀疏的文本数据映射为低维稠密的向量表示，是实现语义检\n索的核心。",
    "type": "单选题",
    "id": "588"
  },
  {
    "question": "在使用 LlamaIndex 构建 RAG 应用时，SimpleDirectoryReader 的作用是什么？",
    "options": [
      "A. 从指定目录加载文件并解析为 Document 对象。",
      "B. 构建向量索引。",
      "C. 将 Document 对象切分为 Node。",
      "D. 对检索结果进行重排序。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "SimpleDirectoryReader 是 LlamaIndex 提供的数据加载器，专门用于从本地目录读取文\n件并转换为框架可处理的 Document 对象。",
    "type": "单选题",
    "id": "589"
  },
  {
    "question": "关于大语言模型微调，以下哪种说法是错误的？",
    "options": [
      "A. 微调是指在预训练模型的基础上，使用特定领域的数据进行进一步训练。",
      "B. 微调可以使模型更好地适应特定任务。",
      "C. 微调需要的数据量通常比预训练少得多。",
      "D. 微调后的模型不再具备预训练模型的通用能力。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "微调是在保留通用能力基础上的特定优化，而非完全丧失通用能力（虽可能出现灾难性\n遗忘，但并非绝对不再具备）",
    "type": "单选题",
    "id": "590"
  },
  {
    "question": "在使用 RAGAS 进行评测时，Context Recall 指标主要反映了什么？",
    "options": [
      "A. 检索到的上下文与正确答案的一致性。",
      "B. 生成的答案与检索到的上下文的一致性。",
      "C. 检索到的上下文是否包含了正确答案所需的信息。",
      "D. 生成的答案与问题的相关性。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Context Recall 衡量的是检索系统找回相关信息的能力，即 Ground Truth 中的信息有\n多少被召回的 Context 覆盖。",
    "type": "单选题",
    "id": "591"
  },
  {
    "question": "关于 RAG 系统的性能优化，以下哪种说法是正确的？",
    "options": [
      "A. 只需要优化检索环节，生成环节完全依赖大模型的能力。",
      "B. 只需要优化生成环节，检索环节使用现成的搜索引擎即可。",
      "C. 需要同时优化检索和生成两个环节，才能获得最佳性能。",
      "D. RAG 系统的性能主要取决于硬件资源，软件优化作用不大。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "RAG 是检索与生成的耦合系统，短板效应明显，必须双管齐下进行优化。",
    "type": "单选题",
    "id": "592"
  },
  {
    "question": "关于大模型的 Temperature 参数，以下哪种说法是正确的？",
    "options": [
      "A. Temperature 值越高，生成的文本越保守、确定。",
      "B. Temperature 值越低，生成的文本越随机、多样。",
      "C. Temperature 值越高，生成的文本越随机、多样。",
      "D. Temperature 参数不影响生成结果。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Temperature 控制采样概率分布的平滑程度，值越高分布越平滑（随机性增加），值越\n低分布越尖锐（确定性增加）。",
    "type": "单选题",
    "id": "593"
  },
  {
    "question": "在 Python 中，使用 re 模块进行正则表达式匹配时，哪个函数用于查找字符串中所有匹配的\n子串？",
    "options": [
      "A. re.match()",
      "B. re.search()",
      "C. re.findall()",
      "D. re.sub()"
    ],
    "answer": [
      "C"
    ],
    "analysis": "A/B 仅匹配一次，D 用于替换，C 返回所有非重叠匹配项的列表",
    "type": "单选题",
    "id": "594"
  },
  {
    "question": "在使用 LlamaIndex 时，VectorStoreIndex 的作用是什么？",
    "options": [
      "A. 将文档存储为向量，并支持向量检索。",
      "B. 将文档存储为关键词索引，支持关键词检索。",
      "C. 将文档存储为树形结构，支持层级检索。",
      "D. 将文档存储为图结构，支持知识图谱检索。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "VectorStoreIndex 是基于向量嵌入的索引结构，专门用于向量相似度检索",
    "type": "单选题",
    "id": "595"
  },
  {
    "question": "关于 RAGAS 评测框架，以下哪种说法是错误的？",
    "options": [
      "A. RAGAS 是一个用于评估 RAG 系统性能的框架。",
      "B. RAGAS 提供了一系列指标，如 Faithfulness、Answer Relevancy 等。",
      "C. RAGAS 需要人工标注大量数据才能进行评测。",
      "D. RAGAS 可以利用大语言模型自动生成评测数据。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "RAGAS 的核心优势之一就是利用 LLM 进行自动化评估，减少对大规模人工标注的依赖",
    "type": "单选题",
    "id": "596"
  },
  {
    "question": "在多模态大模型的应用中，Qwen-VL-Max 主要擅长什么任务？",
    "options": [
      "A. 文本生成",
      "B. 语音识别",
      "C. 图像理解与生成",
      "D. 视频剪辑"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Qwen-VL 系列是视觉语言模型，核心能力在于图像内容的理解与相关生成任务。",
    "type": "单选题",
    "id": "597"
  },
  {
    "question": "在使用大模型进行文本润色时，以下哪个提示词（Prompt）最有效？",
    "options": [
      "A. “帮我改一下这段话。”",
      "B. “这段话写得不好，重写。”",
      "C. “请作为一名专业的编辑，优化以下段落的语言表达，使其更加流畅、专业，并纠正所有语法错误。”",
      "D. “随便改改。”"
    ],
    "answer": [
      "C"
    ],
    "analysis": "C 选项包含了角色设定（专业编辑）、任务目标（优化表达、纠错）、质量要求（流畅、\n专业），符合优质 Prompt 的设计原则。",
    "type": "单选题",
    "id": "598"
  },
  {
    "question": "在 Python 中，如何定义一个类（Class）？",
    "options": [
      "A. function MyClass():",
      "B. def MyClass():",
      "C. class MyClass:",
      "D. struct MyClass:"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Python 使用 class 关键字定义类，无需括号（除非继承），A/D 是其他语言语法，B 用\n于定义函数",
    "type": "单选题",
    "id": "599"
  },
  {
    "question": "在使用阿里云百炼平台时，什么是 “应用（Application）”？",
    "options": [
      "A. 一个具体的 AI 模型。",
      "B. 一个包含模型、知识库、插件等资源的业务逻辑封装。",
      "C. 一个云服务器实例。",
      "D. 一个数据库实例。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "应用是百炼平台的核心概念，集成了模型调用、知识检索、工具使用等能力，对外提供\n业务服务接口。",
    "type": "单选题",
    "id": "600"
  },
  {
    "question": "下列哪种情况不需要进行算法备案？",
    "options": [
      "A. 开发具有舆论属性的生成式 AI 服务。",
      "B. 开发具有社会动员能力的生成式 AI 服务。",
      "C. 开发仅供个人娱乐、不向公众提供的 AI 工具。",
      "D. 开发面向公众的 AI 写作助手。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "根据法规，未向公众提供服务的个人娱乐用途无需备案，其他选项均涉及公众服务或特\n定属性，属于备案范畴。",
    "type": "单选题",
    "id": "601"
  },
  {
    "question": "在 RAG 系统中，Retrieval 阶段的主要任务是？",
    "options": [
      "A. 生成最终答案。",
      "B. 从知识库中检索与问题最相关的文档片段。",
      "C. 对文档进行切片和向量化。",
      "D. 对用户问题进行改写。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Retrieval（检索）的核心定义",
    "type": "单选题",
    "id": "602"
  },
  {
    "question": "以下哪种文件格式最适合存储结构化数据，且易于程序读取？",
    "options": [
      "A. TXT",
      "B. PDF",
      "C. JSON",
      "D. DOCX"
    ],
    "answer": [
      "C"
    ],
    "analysis": "JSON 是键值对结构的轻量级数据交换格式，天然适合结构化数据存储与程序解析。",
    "type": "单选题",
    "id": "603"
  },
  {
    "question": "在使用大模型 API 时，System Role 的主要作用是？",
    "options": [
      "A. 模拟用户的输入。",
      "B. 设定模型的行为模式、角色和背景信息。",
      "C. 存储对话历史。",
      "D. 调整模型的超参数。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "System Role 用于设置“系统指令”或“人设”，是控制模型行为基调的关键。",
    "type": "单选题",
    "id": "604"
  },
  {
    "question": "在向量检索中，Top-K 参数的含义是？",
    "options": [
      "A. 检索结果的相似度阈值。",
      "B. 返回最相似的 K 个结果。",
      "C. 向量的维度。",
      "D. 索引的大小。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Top-K 指截取相似度得分最高的 K 个结果返回",
    "type": "单选题",
    "id": "605"
  },
  {
    "question": "下列哪个不是大模型微调的常见方法？",
    "options": [
      "A. LoRA",
      "B. P-Tuning",
      "C. Full Fine-tuning",
      "D. K-Means"
    ],
    "answer": [
      "D"
    ],
    "analysis": "K-Means 是聚类算法，与模型微调无关。",
    "type": "单选题",
    "id": "606"
  },
  {
    "question": "在 Python 中，pandas 库主要用于？",
    "options": [
      "A. 图像处理",
      "B. 数据分析与处理",
      "C. 网页爬虫",
      "D. 机器学习建模"
    ],
    "answer": [
      "B"
    ],
    "analysis": "pandas 是 Python 生态中最核心的数据分析库，提供 DataFrame 等高效数据结构",
    "type": "单选题",
    "id": "607"
  },
  {
    "question": "在使用大模型进行代码生成时，以下哪个做法是正确的？",
    "options": [
      "A. 盲目信任模型生成的代码，直接运行。",
      "B. 对生成的代码进行审查、测试和验证。",
      "C. 要求模型生成的代码必须包含所有注释。",
      "D. 只使用模型生成简单的代码片段，不生成复杂逻辑。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "模型生成的代码可能存在漏洞或错误，必须经过人工或自动化测试验证才能使用。",
    "type": "单选题",
    "id": "608"
  },
  {
    "question": "关于 AI 智能体（Agent），以下哪种描述最准确？",
    "options": [
      "A. 一个只能回答问题的聊天机器人。",
      "B. 一个具备感知、规划、行动能力的智能系统。",
      "C. 一个用于图像识别的模型。",
      "D. 一个数据库管理系统。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Agent = LLM + Planning + Memory + Tools，强调自主感知环境、规划任务并执行行\n动的闭环能力。",
    "type": "单选题",
    "id": "609"
  },
  {
    "question": "在处理长文档 RAG 时，为什么要进行文档切片（Chunking）？",
    "options": [
      "A. 为了节省存储空间。",
      "B. 为了适应 Embedding 模型和 LLM 的上下文长度限制。",
      "C. 为了提高 OCR 识别率。",
      "D. 为了加密文档内容。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "模型上下文窗口有限，且长文本直接 Embedding 会稀释语义，切片是适配模型限制并\n提升检索精度的必要步骤。",
    "type": "单选题",
    "id": "610"
  },
  {
    "question": "关于阿里云百炼平台的 “知识库”，以下描述正确的是？",
    "options": [
      "A. 只能存储文本文件。",
      "B. 支持多种格式文件上传，并自动进行解析和向量化。",
      "C. 需要用户手动构建向量索引。",
      "D. 不支持对知识库进行检索测试。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "百炼知识库提供一站式服务，支持多格式解析、自动切片向量化及索引构建。",
    "type": "单选题",
    "id": "611"
  },
  {
    "question": "在 Python 中，使用 try...except 语句块的作用是？",
    "options": [
      "A. 定义函数。",
      "B. 循环执行代码。",
      "C. 捕获和处理异常。",
      "D. 导入模块。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "这是 Python 标准的异常处理语法结构",
    "type": "单选题",
    "id": "612"
  },
  {
    "question": "在使用大模型进行多轮对话时，如何保持上下文记忆？",
    "options": [
      "A. 大模型自动记住所有历史对话。",
      "B. 将历史对话记录作为输入的一部分发送给模型。",
      "C. 不需要保持上下文，每轮对话都是独立的。",
      "D. 将历史对话保存到本地文件。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "LLM 本身是无状态的，必须通过将历史对话追加到 Prompt 中（Context Window）来\n实现记忆功能。",
    "type": "单选题",
    "id": "613"
  },
  {
    "question": "关于 AIGC 内容的水印技术，以下哪种说法是正确的？",
    "options": [
      "A. 水印只能是肉眼可见的。",
      "B. 水印可以帮助识别内容的生成来源。",
      "C. 加了水印就一定能防止内容被盗用。",
      "D. 只有图像才能加水印。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "水印（含显式和隐式）的主要功能是溯源和版权标识，而非绝对防盗，且文本、音视\n频均可添加。",
    "type": "单选题",
    "id": "614"
  },
  {
    "question": "在 RAG 系统中，Generator（生成器）通常指的是？",
    "options": [
      "A. 向量数据库。",
      "B. 大语言模型（LLM）。",
      "C. 搜索引擎。",
      "D. 提示词工程。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "RAG 的生成环节由 LLM 负责，基于检索到的上下文生成最终回复。",
    "type": "单选题",
    "id": "615"
  },
  {
    "question": "关于大模型的 “幻觉” 问题，以下哪种描述是正确的？",
    "options": [
      "A. 大模型生成的每一句话都是真实的。",
      "B. 大模型有时会生成看似合理但实际上错误或不存在的信息。",
      "C. 幻觉问题无法解决。",
      "D. 只有小模型才有幻觉问题。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "幻觉（Hallucination）是 LLM 的固有特性，指生成内容与事实不符或逻辑相悖",
    "type": "单选题",
    "id": "616"
  },
  {
    "question": "在 Python 中，requests 库的作用是？",
    "options": [
      "A. 发送 HTTP 请求。",
      "B. 解析 HTML 文档。",
      "C. 处理 Excel 文件。",
      "D. 进行数学计算。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "requests 是 Python 中最常用的 HTTP 客户端库。",
    "type": "单选题",
    "id": "617"
  },
  {
    "question": "以下哪个不是 RAGAS 评测的指标？",
    "options": [
      "A. Faithfulness",
      "B. Answer Relevancy",
      "C. Context Recall",
      "D. Model Size"
    ],
    "answer": [
      "D"
    ],
    "analysis": "Model Size 是模型属性，非 RAG 性能评测指标。",
    "type": "单选题",
    "id": "618"
  },
  {
    "question": "在使用大模型进行创意写作时，提高 Temperature 值会？",
    "options": [
      "A. 降低内容的创新性。",
      "B. 增加内容的多样性和随机性。",
      "C. 限制生成的长度。",
      "D. 提高语法的准确性。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "高 Temperature = 高随机性 = 高创造力（但也伴随高风险）。",
    "type": "单选题",
    "id": "619"
  },
  {
    "question": "关于阿里云 “通义听悟” 的功能，主要包括？",
    "options": [
      "A. 图像生成。",
      "B. 音视频转写、摘要总结、关键词提取。",
      "C. 代码编写。",
      "D. 3D 建模。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "通义听悟专注音视频内容理解与分析",
    "type": "单选题",
    "id": "620"
  },
  {
    "question": "在 RAG 系统中，文档解析失败的最常见原因不包括？",
    "options": [
      "A. 文档加密。",
      "B. 文档格式损坏。",
      "C. 文档内容为空。",
      "D. 向量数据库空间不足。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "向量库空间不足会导致索引或存储失败，而非解析阶段失败（解析发生在入库前）。",
    "type": "单选题",
    "id": "621"
  },
  {
    "question": "以下哪种方式可以有效降低大模型 API 的调用成本？",
    "options": [
      "A. 增加 Prompt 的长度。",
      "B. 使用缓存机制（Cache）存储常见问题的答案。",
      "C. 提高 Temperature 值。",
      "D. 频繁进行微调。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "缓存可避免重复调用 LLM，显著降本增效。",
    "type": "单选题",
    "id": "622"
  },
  {
    "question": "在 Python 中，如何导入一个标准库模块？",
    "options": [
      "A. include module_name",
      "B. import module_name",
      "C. using module_name",
      "D. require module_name"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Python 使用 import 关键字。",
    "type": "单选题",
    "id": "623"
  },
  {
    "question": "关于 AIGC 应用的合规性，开发者应对？",
    "options": [
      "A. 生成的所有内容负责。",
      "B. 用户的非法使用负责。",
      "C. 模型的训练数据来源合法性负责。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "开发者需对全链路合规性负责，包括数据源、生成内容及用户引导。",
    "type": "单选题",
    "id": "624"
  },
  {
    "question": "在 RAG 流程中，Re-ranking（重排序）的作用是？",
    "options": [
      "A. 对初始检索结果进行精细化排序，提升相关性。",
      "B. 重新生成文档的向量。",
      "C. 对用户问题进行重写。",
      "D. 对生成结果进行语法检查。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Re-ranking 利用 Cross-Encoder 等高精度模型对召回结果二次筛选，是提升 RAG 精\n度的关键技术。",
    "type": "单选题",
    "id": "625"
  },
  {
    "question": "以下哪个工具可以帮助构建 AI 智能体工作流？",
    "options": [
      "A. LangChain",
      "B. NumPy",
      "C. Matplotlib",
      "D. Scikit-learn"
    ],
    "answer": [
      "A"
    ],
    "analysis": "LangChain 是当前最主流的 LLM 应用编排框架。",
    "type": "单选题",
    "id": "626"
  },
  {
    "question": "在使用大模型 API 时，Max Tokens 参数控制的是？",
    "options": [
      "A. 输入文本的最大长度。",
      "B. 生成文本的最大长度。",
      "C. API 调用的最大并发数。",
      "D. 模型的参数量。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Max Tokens 限制模型输出的 Token 数量上限。",
    "type": "单选题",
    "id": "627"
  },
  {
    "question": "关于 Python 的 json.dumps() 函数，以下说法正确的是？",
    "options": [
      "A. 将 JSON 字符串转换为 Python 对象。",
      "B. 将 Python 对象转换为 JSON 字符串。",
      "C. 读取 JSON 文件。",
      "D. 写入 JSON 文件。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "dumps = dump string，即将对象序列化为字符串。",
    "type": "单选题",
    "id": "628"
  },
  {
    "question": "在 RAGAS 评测中，Answer Correctness 主要评估？",
    "options": [
      "A. 答案的流畅度。",
      "B. 答案是否包含敏感词。",
      "C. 答案与标准答案（Ground Truth）在事实层面的一致性。",
      "D. 检索速度。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Answer Correctness 衡量生成结果的准确性。",
    "type": "单选题",
    "id": "629"
  },
  {
    "question": "以下哪种场景最适合使用 Agent（智能体）？",
    "options": [
      "A. 简单的问答。",
      "B. 文本翻译。",
      "C. 需要调用外部工具（如搜索、计算器、API）完成的复杂任务。",
      "D. 文本分类。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Agent 的核心价值在于工具使用（Tool Use）和多步规划，解决单一 LLM 无法处理的\n任务。",
    "type": "单选题",
    "id": "630"
  },
  {
    "question": "在模型微调中，Epochs 表示？",
    "options": [
      "A. 训练数据的批次大小。",
      "B. 学习率。",
      "C. 整个训练数据集被模型遍历的次数。",
      "D. 模型的层数。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Epoch 定义：全量数据完成一次训练循环。",
    "type": "单选题",
    "id": "631"
  },
  {
    "question": "关于阿里云百炼平台的 “插件（Plugin）”，其作用是？",
    "options": [
      "A. 美化界面。",
      "B. 扩展大模型的能力，使其能连接外部服务或数据。",
      "C. 加速模型推理。",
      "D. 降低调用成本。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "插件是连接 LLM 与真实世界的桥梁（如联网搜索、代码执行等）。",
    "type": "单选题",
    "id": "632"
  },
  {
    "question": "在 Python 中，f-string 的主要作用是？",
    "options": [
      "A. 定义浮点数。",
      "B. 定义函数。",
      "C. 格式化字符串，支持嵌入变量和表达式。",
      "D. 文件操作。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "f-string（如 f\"Hello {name}\"）是 Python 3.6+ 引入的高效字符串格式化方式",
    "type": "单选题",
    "id": "633"
  },
  {
    "question": "以下哪个步骤不属于 RAG 的基本流程？",
    "options": [
      "A. 文档切片。",
      "B. 向量检索。",
      "C. 模型预训练。",
      "D. 上下文生成。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "RAG 利用现成模型进行增强，预训练是模型开发阶段的工作，不属于 RAG 运行时流\n程。",
    "type": "单选题",
    "id": "634"
  },
  {
    "question": "关于大模型的 “上下文窗口（Context Window）”，以下说法正确的是？",
    "options": [
      "A. 窗口越小越好。",
      "B. 窗口大小限制了模型单次能处理的输入和输出总 Token 数。",
      "C. 窗口大小是无限的。",
      "D. 窗口大小只影响输入，不影响输出。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Context Window 是模型的硬性约束，决定了其能“记住”多少即时信息。",
    "type": "单选题",
    "id": "635"
  },
  {
    "question": "在 LlamaIndex 中，Document 对象主要包含？",
    "options": [
      "A. 文本内容和元数据。",
      "B. 只有文本内容。",
      "C. 只有文件名。",
      "D. 向量数据。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Document 是数据载体，包含 text（内容）和 metadata（源信息、时间等）。",
    "type": "单选题",
    "id": "636"
  },
  {
    "question": "关于 “提示词注入（Prompt Injection）” 攻击，以下描述正确的是？",
    "options": [
      "A. 向模型注入病毒。",
      "B. 通过精心设计的输入，诱导模型忽略原有指令并执行恶意操作。",
      "C. 提高模型的响应速度。",
      "D. 优化提示词结构。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Prompt Injection 是针对 LLM 的典型安全威胁，类似 SQL 注入。",
    "type": "单选题",
    "id": "637"
  },
  {
    "question": "在 Python 中，len() 函数的作用是？",
    "options": [
      "A. 计算对数。",
      "B. 获取对象（如列表、字符串）的长度。",
      "C. 将字符串转换为小写。",
      "D. 删除列表元素。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "len = length。",
    "type": "单选题",
    "id": "638"
  },
  {
    "question": "在使用大模型 API 时，stream=True 参数表示？",
    "options": [
      "A. 开启视频流。",
      "B. 开启流式输出，逐个 Token 返回结果。",
      "C. 开启音频流。",
      "D. 开启多线程处理。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "流式输出能显著降低首字延迟（TTFT），提升用户体验。",
    "type": "单选题",
    "id": "639"
  },
  {
    "question": "以下哪种方式不适合用于 RAG 的文档切片？",
    "options": [
      "A. 按固定字符数切分。",
      "B. 按句子切分。",
      "C. 按语义完整性切分。",
      "D. 随机切分。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "随机切分会彻底破坏语义连贯性，导致检索失效。",
    "type": "单选题",
    "id": "640"
  },
  {
    "question": "关于阿里云百炼平台的 “流程编排”，其主要功能是？",
    "options": [
      "A. 编写 Python 代码。",
      "B. 通过可视化方式串联模型、插件、知识库等节点，构建复杂 AI 应用。",
      "C. 管理服务器集群。",
      "D. 设计数据库表结构。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "可视化编排降低了复杂 Agent/Workflow 的开发门槛。",
    "type": "单选题",
    "id": "641"
  },
  {
    "question": "在微调过程中，过拟合（Overfitting）的表现是？",
    "options": [
      "A. 训练集 loss 下降，验证集 loss 下降。",
      "B. 训练集 loss 上升，验证集 loss 上升。",
      "C. 训练集 loss 下降，验证集 loss 上升。",
      "D. 训练集 loss 不变，验证集 loss 不变。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "过拟合指模型死记硬背训练数据，导致泛化能力下降（验证集表现变差）。",
    "type": "单选题",
    "id": "642"
  },
  {
    "question": "以下哪个 Python 库常用于科学计算和矩阵运算？",
    "options": [
      "A. Django",
      "B. Flask",
      "C. NumPy",
      "D. Scrapy"
    ],
    "answer": [
      "C"
    ],
    "analysis": "NumPy 是 Python 科学计算的基石。",
    "type": "单选题",
    "id": "643"
  },
  {
    "question": "关于 “思维链（Chain of Thought, CoT）” 提示技术，以下说法正确的是？",
    "options": [
      "A. 只能用于数学题。",
      "B. 引导模型展示推理步骤，从而提高复杂任务的准确率。",
      "C. 会降低模型的推理速度，应尽量避免。",
      "D. 不需要任何示例，模型自动具备。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "CoT 通过显式推理路径激发模型的逻辑能力。",
    "type": "单选题",
    "id": "644"
  },
  {
    "question": "在 RAG 系统中，混合检索（Hybrid Search）通常是指？",
    "options": [
      "A. 同时使用 Google 和 Bing 搜索。",
      "B. 结合关键词检索（BM25）和向量检索（Dense Retrieval）。",
      "C. 同时使用多个大模型生成答案。",
      "D. 结合文本和图像检索。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "混合检索互补了关键词匹配（精确匹配）和向量检索（语义匹配）的优势。",
    "type": "单选题",
    "id": "645"
  },
  {
    "question": "关于大模型的 “Token”，以下描述最准确的是？",
    "options": [
      "A. 就是一个单词。",
      "B. 就是一个字符。",
      "C. 模型处理文本的最小单位，可能是一个字、词的一部分或整个词。",
      "D. 就是一行文本。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Token 是 BPE 等分词算法的产物，中文通常 1 Token ≈ 0.6~0.7 汉字。",
    "type": "单选题",
    "id": "646"
  },
  {
    "question": "在使用 LlamaIndex 时，ServiceContext（或 Settings）主要用于配置？",
    "options": [
      "A. 网络连接。",
      "B. 全局组件，如 LLM、Embedding 模型、Chunk Size 等。",
      "C. 用户界面。",
      "D. 数据库连接字符串。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "ServiceContext 是 LlamaIndex 的全局配置中心（新版已迁移至 Settings）。",
    "type": "单选题",
    "id": "647"
  },
  {
    "question": "以下哪种措施不能有效防止 Prompt Injection？",
    "options": [
      "A. 对用户输入进行严格验证和过滤。",
      "B. 使用分隔符清晰区分指令和数据。",
      "C. 仅仅依靠在 Prompt 中添加“请忽略后续指令”的说明。",
      "D. 监控和审计异常输入。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "仅靠自然语言防御（C）很容易被绕过，必须结合工程手段防御。",
    "type": "单选题",
    "id": "648"
  },
  {
    "question": "以下哪种做法不符合利用大模型提升开发效率的思路？",
    "options": [
      "A. 对于所有类型的图片，都使用视觉模型进行深层次解析，以确保信息的完整性。",
      "B. 使用 DashScopeParse 解析文档，而不是自己编写复杂的解析逻辑。",
      "C. 将复杂的文档处理任务拆分成多个子任务，分别使用不同的模型或工具处理。",
      "D. 对于简单的文本替换操作，使用正则表达式而不是调用大模型 API。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "649"
  },
  {
    "question": "要将索引持久化到磁盘，应使用以下哪个方法？",
    "options": [
      "A. index.store()",
      "B. index.persist()",
      "C. index.save()",
      "D. index.storage_context.persist()"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "650"
  },
  {
    "question": "已知 prompt_template 定义了让大模型生成摘要的具体要求，以下哪些措施可以提高摘\n要生成函数的生成质量？",
    "options": [
      "A. 将 document 分成多个段落，分别生成摘要，最后合并。",
      "B. 在 prompt_template 中明确指出需要提取文章的主旨。",
      "C. 不使用 prompt_template，直接调用大模型。",
      "D. 在 prompt_template 中提供一些示例摘要。",
      "E. 在 prompt_template 中提供更详细的输出格式要求，例如指定摘要的长度、语气等。"
    ],
    "answer": [
      "A",
      "B",
      "D",
      "E"
    ],
    "analysis": "C 无提示模板会导致输出不可控，质量波动大，完全依赖模型的默认行为，难以满足特\n定需求。",
    "type": "多选题",
    "id": "651"
  },
  {
    "question": "你正在开发一个机器学习领域的答疑机器人，辅助学生学习，但你对该领域专业知识掌握\n有限，以下哪些策略更有助于你改进提示词设计？",
    "options": [
      "A. 邀请机器学习课程助教一起审核和改进提示词，要求其按照一定的结构来回答问题",
      "B. 要求大模型扮演「机器学习教授」，结合学生认知水平，重新写出更结构化的提示词",
      "C. 按照自己的理解要求大模型按照一定的结构来回答问题",
      "D. 保持提示词简单，避免引入错误的信息"
    ],
    "answer": [
      "A",
      "B"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "652"
  },
  {
    "question": "()关于多模态技术底层原理，正确的说法是？",
    "options": [
      "A. 图像理解模型也需要先将视频或图像分词化再做处理",
      "B. 实现「方言语音合成」需要训练模型建立方言音素与标准发音的映射关系",
      "C. 视频合成所花费的时间与可用的算力呈负相关",
      "D. 文生图模型生成不同尺寸图像时，必须重新训练模型"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "653"
  },
  {
    "question": "一家旅游公司计划推出一款沉浸式个性化 AI 导游产品，以下哪些功能设计可以有效提升\n产品的吸引力和实用性？",
    "options": [
      "A. 使用大语言模型为游客实时生成个性化的景点介绍，结合游客的兴趣和历史游览记录。",
      "B. 开发一个路径规划系统，根据实时交通和天气情况为游客推荐最佳游览路线。",
      "C. 利用图像识别技术分析游客拍摄的照片，自动标注景点名称并提供相关背景信息。",
      "D. 提供一个语音讲解的随身 pad，确保所有游客听到的内容完全相同。"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "654"
  },
  {
    "question": "某金融智能风控系统在高峰期偶尔出现模型不可用的情况，以下哪些方案可以作为降级策\n略？",
    "options": [
      "A. 增加 GPU 实例数量",
      "B. 切换至规则引擎兜底",
      "C. 使用备份模型继续服务",
      "D. 关闭部分非核心功能"
    ],
    "answer": [
      "B",
      "C",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "655"
  },
  {
    "question": "一家教育科技公司拟开发 AI 教学产品，以下哪些方案能体现 “个性化、智能化、普惠\n教育”？",
    "options": [
      "A. 自适应学习平台根据学生水平动态调整题库",
      "B. 用 VR 实验室模拟替代昂贵的物理实验，降低教学成本",
      "C. 方言识别系统辅助少数民族学生练习普通话",
      "D. 选择题自动判卷，问答题错别字纠正"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "656"
  },
  {
    "question": "某跨境电商平台的客服系统需要处理多语言用户咨询，在进行文本合规检查时发现部分违\n规内容无法被检测出来。哪两个方案能提供多语言文本的合规检查效果？",
    "options": [
      "A. 强制要求用户使用英语提问，其他语言咨询转入人工处理",
      "B. 建立多语言同义词库，覆盖常见违规表述的变体（如 “免税代购” 的谐音 / 缩写形式）",
      "C. 使用跨语言语义理解模型，识别违规意图而非依赖关键词匹配",
      "D. 将非英语内容翻译为英语后复用单语种审核规则"
    ],
    "answer": [
      "B",
      "C"
    ],
    "analysis": "覆盖变体和语义理解结合能显著提升多语言合规检查效果",
    "type": "多选题",
    "id": "657"
  },
  {
    "question": "当你在使用一款基于大模型构建的创意助手，要求它一次性产生 10 条宣传文案时，发现\n生成的文案千篇一律，缺乏多样性。为了在保证一定多样性的同时避免模型生成不符合主题的\n内容，可以优先考虑以下哪些改进措施？",
    "options": [
      "A. 使用模糊的指令，让模型自由发挥。",
      "B. 检查提示词是否过于局限，尝试在提示词中明确指定多个角度方向（如情感、风格、视角等） 来扩展其灵活性。",
      "C. 固定 top_p=0.1 以确保最大范围的词汇选择。",
      "D. 小幅调高 temperature 以保证生成内容的多样性。"
    ],
    "answer": [
      "B",
      "D"
    ],
    "analysis": "B 提供结构化多样性引导，D 增加适当随机性，两者结合可优化生成效果",
    "type": "多选题",
    "id": "658"
  },
  {
    "question": "用户多次反馈 “AI 回答中有捏造内容”，排查后发现是当知识库没有相关内容时，大模\n型直接虚构答案。为减少此情况，你可以怎么做？",
    "options": [
      "A. 在百炼 RAG 应用中将回答范围设置为 “仅知识库范围”",
      "B. 调高 temperature 值",
      "C. 使用 ReRank 对检索结果再次排序",
      "D. 使用提示词，无匹配就明确回复 “无法回答”"
    ],
    "answer": [
      "A",
      "D"
    ],
    "analysis": "A 适用于严格依赖知识库的场景，D 作为兜底策略，两者均可减少幻觉。C 可辅助提升\n检索质量，但非必需；B 完全错误",
    "type": "多选题",
    "id": "659"
  },
  {
    "question": "某电商公司需开发一个客服机器人处理 “退换货政策咨询” 和 “商品推荐” 任务，下\n列哪两种角色应该深度参与提示词设计？",
    "options": [
      "A. 产品经理（定义用户场景和业务流程）",
      "B. 前端开发工程师（负责对话界面实现）",
      "C. 算法工程师（擅长模型调优和参数调整）",
      "D. 客服部门主管（熟悉用户高频问题和政策细节）"
    ],
    "answer": [
      "A",
      "D"
    ],
    "analysis": "产品经理和客服主管是提示词设计的核心角色，分别从流程和内容层面保证机器人符合\n业务需求。\n其他角色（B C）更多是执行或技术支持，无需深度参与设计。",
    "type": "多选题",
    "id": "660"
  },
  {
    "question": "你需要大模型从客户邮件中提取结构化数据（如姓名、订单号、问题类型），以下哪两个\n选项有助于你达成这一目标？",
    "options": [
      "A. 提供你期望的 JSON 结构示例",
      "B. 调低温度参数（Temperature）以降低随机性",
      "C. 在任务目标中明确 “输出 JSON 格式”",
      "D. 要求模型分两步操作，先总结邮件内容，再提取字段"
    ],
    "answer": [
      "A",
      "C"
    ],
    "analysis": "字段复杂，可追加示例邮件+对应 JSON，增强模型理解。使用函数调用直接绑定 JSON\nSchema，进一步标准化输出",
    "type": "多选题",
    "id": "661"
  },
  {
    "question": "关于 temperature 和 top_p参数的作用，以下哪三个描述是正确的?",
    "options": [
      "A. 较低的 top_p 可以提高生成内容的稳定性",
      "B. 较低的 temperature 可以增加生成内容的多样性",
      "C. 通常情况下，只需调整其中一个参数即可。",
      "D. 较高的 temperature 可以增加生成内容的多样性"
    ],
    "answer": [
      "A",
      "C",
      "D"
    ],
    "analysis": "B 错 低 temperature → 稳定性↑，多样性↓高 temperature → 稳定性↓，多样性↑",
    "type": "多选题",
    "id": "662"
  },
  {
    "question": "以下哪些方案，有助于提升大模型应用的用户体验？",
    "options": [
      "A. 等全部内容生成后一次性返回",
      "B. 展示任务处理进度",
      "C. 生成的内容流式输出",
      "D. 将任务分解为多个步骤，并且将分步执行过程展示给用户"
    ],
    "answer": [
      "B",
      "C",
      "D"
    ],
    "analysis": "提升用户体验的核心是 减少等待焦虑 和 增强交互透明性",
    "type": "多选题",
    "id": "663"
  },
  {
    "question": "下列哪些 AIGC 应用场景需要进行算法备案？",
    "options": [
      "A. 基于 AIGC 的智能客服系统",
      "B. 使用机器学习算法进行数据分析的企业内部工具",
      "C. 基于大模型的 AI 写作工具",
      "D. 利用深度学习进行图像生成的绘画软件"
    ],
    "answer": [
      "A",
      "C",
      "D"
    ],
    "analysis": "无需备案：仅限企业内部使用，不向公众开放，不符合“向境内公众提供”的备案条件",
    "type": "多选题",
    "id": "664"
  },
  {
    "question": "选择 LoRA 权重时需考虑哪些因素？",
    "options": [
      "A. GPU 显存容量",
      "B. 训练数据量",
      "C. 任务复杂度",
      "D. 基础模型参数量"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "665"
  },
  {
    "question": "你发现大量员工信息都存放在 PDF、Word 文档里，部分还包含表格和图片，RAG 无法正\n确提取关键信息。你可以怎么处理？",
    "options": [
      "A. 手动复制粘贴所有文档内容",
      "B. 使用 OCR 技术识别并提取图片中的文字",
      "C. 强制用户只上传纯文本",
      "D. 使用 DashScopeParse 等工具，对 PDF/Word 进行结构化解析"
    ],
    "answer": [
      "B",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "666"
  },
  {
    "question": "RAG 应用在检索时共召回了 10 条切片，其中 3 条高度相关，但 3 条内容都来自相邻段\n落，却被系统拆分成不同切片，从而导致回答时缺失连贯的上下文信息。哪些方案可进一步提\n升答案准确度？",
    "options": [
      "A. 采用滑动窗口策略生成重叠的文本切片",
      "B. 使用按照语义的切片策略，切分出语义更完整的切片",
      "C. 提高 temperature 参数控制生成多样性",
      "D. 调整切片大小使其覆盖完整更大段落范围"
    ],
    "answer": [
      "A",
      "B",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "667"
  },
  {
    "question": "你正在优化一个 RAG 系统，发现某些相似文本对的向量相似度较低，以下哪两种方法可\n以改善这种情况？",
    "options": [
      "A. 更换效果更好的 embedding 模型",
      "B. 将索引保存到本地并在运行时加载",
      "C. 减少向量数据库的存储容量",
      "D. 通过对比学习让相关文本对的向量相似度更高"
    ],
    "answer": [
      "A",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "668"
  },
  {
    "question": "你在开发的招聘答疑机器人，在回答 “产品经理的岗位职责有哪些” 时，输出的职责经\n常包含客户经理的工作职责。经排查发现，不同岗位的说明文档使用了相同的模板，文档切片\n时经常将 #客户经理# 岗位和 #产品经理# 岗位的职责主要是这样描述的。以下哪两种方法能\n有效解决这个问题？",
    "options": [
      "A. 使用 ReRank 对检索结果再次排序",
      "B. 在处理文档时，对于文档中的二级标题，自动拼接文档名称，如 ## 岗位职责 会被拼接为 ## 客户经理 - 岗位职责",
      "C. 在建立索引时，以文档名称建立标签，检索阶段使用标签 + 向量混合检索",
      "D. 调高大模型 temperature 参数，提高大模型匹配正确答案数据的概率"
    ],
    "answer": [
      "B",
      "C"
    ],
    "analysis": "A 选项：通过文档名称建立标签，检索时结合标签（岗位名称）和向量混合检索，能精\n准限定检索内容，避免其他岗位内容混入，有效。B temperature 参数控制生成的随机性，调\n高它无法解决检索时内容混淆的根本问题，无效。C 给二级标题拼接文档名称（岗位名称），使\n段落带上明确岗位标识，检索时能准确区分，避免混淆，有效。D ReRank 仅对检索结果重新排\n序，不解决内容混淆的根源，仍会包含其他岗位段落，无效。",
    "type": "多选题",
    "id": "669"
  },
  {
    "question": "在多轮对话场景中，以下哪些方案，更有利于保障用户体验的同时，降低大模型使用成本？",
    "options": [
      "A. 在多轮对话场景中使用支持长上下文缓存的大模型 API",
      "B. 每次对话仅保留最近 2 轮历史，避免携带过长的上下文",
      "C. 按照 100 的长度，对历史对话取截断，避免携带上下文过长",
      "D. 在多轮对话场景中，避免始终传入完整的历史对话，而是用最早的历史对话做总结处理后携 带在对话中"
    ],
    "answer": [
      "A",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "670"
  },
  {
    "question": "你在构建一个 RAG 应用，以下哪些提示词模板是合理的？",
    "options": [
      "A. 检索到的相关内容为，{检索到的文本段} 用户的问题是，{用户问题} 请结合以上信息，给出准确且简洁的回答。",
      "B. 以下是用户的问题，{用户问题}",
      "C. 以下是与问题相关的背景信息，{检索到的文本段} 问题是，{用户问题} 请基于背景信息，提供一个合理且完整的答案。",
      "D. 以下是检索到的内容，{检索到的文本段}"
    ],
    "answer": [
      "A",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "671"
  },
  {
    "question": "对于 RAG 应用的理解，以下哪两项描述是正确的？",
    "options": [
      "A. RAG 中的 “R”（Retrieval，检索）通常依赖专门的检索模块，从外部知识库中提取与输入 问题最相关的文本信息，为后续解答提供依据",
      "B. 在 RAG 框架中，大模型仅起信息汇总作用，即便其本身不熟悉某些领域的知识，也一定可以 凭借总结能力准确回答问题",
      "C. RAG 的 “G”（Generation，生成），指的是大模型在得到参考知识与输入问题后进行回答的 过程",
      "D. RAG 的 “A”（Augmented，增强），是通过提示词来实时训练模型，达到增强模型的效果"
    ],
    "answer": [
      "A",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "672"
  },
  {
    "question": "你负责的短视频平台在接入多模态技术后出现故障。\n1：用户输入 “生成夏日海滩 vlog 背景” 时，系统返回静态图片而非视频\n2：视频自动剪辑功能无法识别冲浪板等特定物体\n3：添加的 AI 解说语音与动画动作不同步\n需要重点检查的技术环节是？",
    "options": [
      "A. 视频编辑时是否设置了正确的时间轴",
      "B. 图像理解模型可能缺少对特定场景的训练数据",
      "C. 仅使用了文生图模型来生成完整视频",
      "D. 语音合成模型采样率不合适导致视频音画不同步"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "673"
  },
  {
    "question": "在决定模型微调前，你应该考虑以下哪些事情？",
    "options": [
      "A. 训练数据量是否达到微调的最低标准",
      "B. 该任务是否更适合使用 RAG",
      "C. 提示词工程是否能达到预期效果",
      "D. 训练服务器资源的成本"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "674"
  },
  {
    "question": "某教育问答系统上线后，你通过监控日志发现模型有时会返回个人隐私信息，为防止此类\n敏感信息泄露，可以采取以下哪三项措施？",
    "options": [
      "A. 过滤用户提问，避免诱导性问题",
      "B. 在问答系统流式返回内容时，实时检测并过滤敏感信息",
      "C. 增加知识库内容的多样性，减少隐私信息被召回的概率",
      "D. 对教育知识库的内容进行脱敏处理"
    ],
    "answer": [
      "B",
      "C",
      "D"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "675"
  },
  {
    "question": "你正在基于某视觉理解大模型开发一个门店巡检系统（检查垃圾桶是否盖好、操作是否整\n洁、水池是否洗干净等），但发现用大模型同时识别判断场景、给出判断结果的效果总是不好，\n以下哪种改进方案能更低成本地解决这一问题？",
    "options": [
      "A. 增加更多的监控摄像头，给大模型更多的输入信息",
      "B. 收集一批高质量的监控画面数据，面向巡检任务微调大模型",
      "C. 改进当前的数据输入，减少监控画面的分辨率，避免引入干扰信息",
      "D. 用物体分割小模型圈出识别区域，然后抠图输入给大模型检测状态"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "676"
  },
  {
    "question": "某企业需要部署一个大模型，不定期自动地分析现有的产品文档，并产出改进建议，以下\n哪一种计费方式可以在满足业务需求的同时最大化降低运行成本？：",
    "options": [
      "A. 通过按量付费方式创建 GPU 资源",
      "B. 使用抢占式实例（Spot Instance），同时设计好任务中断的自动恢复机制",
      "C. 购买显卡并搭建本地服务器",
      "D. 通过预付费（包年包月）方式创建 GPU 资源"
    ],
    "answer": [
      "B"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "677"
  },
  {
    "question": "你需要在资源受限的环境下部署一个大模型，以下哪种方案有助于你减少对显存的需求？",
    "options": [
      "A. 蒸馏小模型，训练一个更小参数量的模型",
      "B. 扩大允许的输入 Token 长度",
      "C. 微调现有模型，改善其效果",
      "D. 提高模型批量任务的数量"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "678"
  },
  {
    "question": "使用 LoRA 微调时，训练损失波动剧烈，以下哪种策略有可能解决这一问题？",
    "options": [
      "A. 继续训练，无须调整",
      "B. 把 batch_size 从 16 调到 4",
      "C. 将 lora_rank 从 8 提升到 32",
      "D. 将学习率降低至原来的 10 分之一"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "679"
  },
  {
    "question": "你准备为企业内部人事系统搭建一个多轮问答功能，现有历史对话“张三的办公楼在哪？”，\n在 A 轮 “他的主管是谁？”，你应该怎么设计检索步骤？",
    "options": [
      "A. 对 “主管” 进行同义词扩展，包含 “领导”、“上级” 等，提高召回率",
      "B. 提高检索的相似度阈值，确保不包含无用信息",
      "C. 混合使用关键词检索与向量检索策略",
      "D. 结合对话历史改写 query，再进行检索"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "680"
  },
  {
    "question": "你在需要构建公文智能处理系统，用户上传 PDF 文件，系统需自动识别文本内容并生成\n摘要。以下哪种架构设计比较合理？",
    "options": [
      "A. 前端上传文件至 FC，FC 调用 OCR 服务提取文本并存入 OSS，再由百炼模型提供结果链接",
      "B. 前端直接调用百炼模型解析 PDF，模型将原始文件和分析结果存入 OSS，通过访问链接提供 结果的访问",
      "C. OSS 仅存储最终摘要文件，原始 PDF 通过 FC 直传至百炼模型服务进行全流程处理",
      "D. 前端上传 PDF 至 OSS，触发 FC 解析文本，FC 调用百炼模型生成摘要，结果存入 OSS 并前 端下载"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "681"
  },
  {
    "question": "某社交平台需自动屏蔽违规评论，要求同时处理文字、图片。以下哪种方案更合理？",
    "options": [
      "A. 延迟显示所有 AI 生成内容等待人工审核",
      "B. 建立独立的关键词库分别过滤文本和图片",
      "C. 要求用户上传内容前手动选择内容分类标签",
      "D. 使用多模态模型拦截图文混合违规内容，如 qwen - v1 72b"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "682"
  },
  {
    "question": "某电商平台计划使用 RAG 模型构建智能客服系统，帮助用户查询商品信息。以下关于该\n系统的评测方法，哪一项是正确的？",
    "options": [
      "A. 生成模块是系统的核心，应优先优化生成阶段的知识总结能力。",
      "B. 应重点评估检索模块的表现，因为商品信息的准确性和相关性直接影响最终生成的结果。",
      "C. 应对检索阶段和生成阶段分别进行评测，以便全面优化系统性能。",
      "D. 评测时只需关注最终回答的准确性，因为用户的满意度主要取决于答案是否正确。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "RAG 是检索 + 生成的配合，评测必须同时关注两步，才能真正优化系统就像考试既要练\n知识点，也要练答题技巧",
    "type": "单选题",
    "id": "683"
  },
  {
    "question": "某公司推出了一款 “大小模型协同” 系统，使用小模型处理常规问答，大模型处理复杂\n推理或文档分析。系统还采用了多智能体架构，然而系统经常把一些简单 FAQ 也交给大模型处\n理，浪费了算力。为了解决该问题，以下哪种做法最有效？",
    "options": [
      "A. 在 Planner Agent 中增加任务复杂度判断逻辑，优先调用小模型处理简单 FAQ",
      "B. 对小模型进行额外训练，提升其对更多类型问题的处理能力，从而减轻大模型负担",
      "C. 在工具函数描述中添加更多示例，让大模型能更准确区分不同请求的复杂度",
      "D. 为 Summary Agent 提供更多训练数据，确保最终回答更加全面"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "684"
  },
  {
    "question": "在构建微调数据集时，以下哪个方面的考量是错误的？",
    "options": [
      "A. 数据集要根据微调效果持续迭代",
      "B. 要包括任务全场景",
      "C. 测试集内容要包含在训练集中",
      "D. 要确保数据集准确、内容相关"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "685"
  },
  {
    "question": "在对大语言模型进行微调时，以下哪个操作有助于防止过拟合？",
    "options": [
      "A. 增加训练轮数",
      "B. 使用早停法",
      "C. 使用更复杂的模型",
      "D. 减少训练数据量"
    ],
    "answer": [
      "B"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "686"
  },
  {
    "question": "在模型微调过程中，发现训练 Loss 震荡不收敛，可能的原因是？",
    "options": [
      "A. 学习率过大",
      "B. 训练轮数太少",
      "C. 显存不足",
      "D. 验证集数据量太小"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "687"
  },
  {
    "question": "以下哪种技术最适合用于处理长文档的检索？",
    "options": [
      "A. 全文搜索",
      "B. 向量检索",
      "C. 混合检索（Hybid Search）",
      "D. 关键词检索"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "688"
  },
  {
    "question": "在使用大模型进行翻译时，以下哪个提示词效果最好？",
    "options": [
      "A. “翻译一下。”",
      "B. “把这段话翻译成英文。”",
      "C. “你是一名专业的翻译，请将以下中文翻译成地道的英文，并保持原文的风格。”",
      "D. “随便翻。”"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "689"
  },
  {
    "question": "在 RAG 系统中，ReRank 模型通常部署在哪个环节之后？",
    "options": [
      "A. 文档解析",
      "B. 向量检索",
      "C. 生成答案",
      "D. 提示词工程"
    ],
    "answer": [
      "B"
    ],
    "analysis": "ReRank 是对初步召回的候选集进行精排序，必须位于向量检索（召回）之后。",
    "type": "单选题",
    "id": "690"
  },
  {
    "question": "以下哪种方式可以提高 RAG 系统对表格数据的理解能力？",
    "options": [
      "A. 将表格转换为 JSON 格式。",
      "B. 将表格转换为 Markdown 格式。",
      "C. 对表格进行单独的切片处理。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "这三种方法均能从不同维度保留表格结构信息，结合使用效果更佳。",
    "type": "单选题",
    "id": "691"
  },
  {
    "question": "在使用大模型进行多模态任务时，Vision Encoder 的作用是？",
    "options": [
      "A. 生成图像。",
      "B. 将图像转换为向量表示。",
      "C. 识别图像中的文字。",
      "D. 对图像进行分类。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Vision Encoder 是视觉信息的编码器，负责将像素信息转化为模型可理解的向量",
    "type": "单选题",
    "id": "692"
  },
  {
    "question": "在 Python 中，如何读取一个 CSV 文件？",
    "options": [
      "A. 使用 open() 函数。",
      "B. 使用 pandas.read_csv() 函数。",
      "C. 使用 csv.reader() 函数。",
      "D. 以上都可以。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "A 是底层文件操作，C 是标准库，B 是数据分析常用库，三者均可实现。",
    "type": "单选题",
    "id": "693"
  },
  {
    "question": "以下哪个不是 Agent 的核心组件？",
    "options": [
      "A. Planning（规划）",
      "B. Memory（记忆）",
      "C. Tools（工具）",
      "D. Database（数据库）"
    ],
    "answer": [
      "D"
    ],
    "analysis": "数据库是外部存储设施，Agent 的核心组件是 LLM+规划+记忆+工具（Action）。",
    "type": "单选题",
    "id": "694"
  },
  {
    "question": "在 RAGAS 评测中，Context Precision 主要评估？",
    "options": [
      "A. 检索到的文档是否包含正确答案。",
      "B. 检索到的文档中，相关文档的排名是否靠前。",
      "C. 生成的答案是否准确。",
      "D. 检索速度。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Context Precision 关注的是检索结果的排序质量（即相关内容是否排在前面）",
    "type": "单选题",
    "id": "695"
  },
  {
    "question": "在使用大模型 API 时，System Message 和 User Message 的区别是？",
    "options": [
      "A. 没有区别。",
      "B. System Message 设定模型的行为，User Message 是用户的具体指令。",
      "C. System Message 是用户的输入，User Message 是模型的回复。",
      "D. System Message 是可选的，User Message 是必须的。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "System 设定“你是谁”，User 设定“做什么”。",
    "type": "单选题",
    "id": "696"
  },
  {
    "question": "以下哪种情况适合使用 Function Calling（函数调用）？",
    "options": [
      "A. 需要模型查询实时天气。",
      "B. 需要模型进行复杂的数学计算。",
      "C. 需要模型操作数据库。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "Function Calling 旨在扩展 LLM 能力边界，涵盖实时信息获取、精确计算及外部系\n统操作。",
    "type": "单选题",
    "id": "697"
  },
  {
    "question": "在模型微调中，Learning Rate（学习率）过大会导致？",
    "options": [
      "A. 训练速度变慢。",
      "B. 模型无法收敛，Loss 震荡。",
      "C. 模型过拟合。",
      "D. 模型欠拟合。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "学习率过大导致梯度更新步长过大，直接跳过最优解（震荡不收敛）。",
    "type": "单选题",
    "id": "698"
  },
  {
    "question": "关于阿里云百炼平台的 “Prompt 模板”，以下说法正确的是？",
    "options": [
      "A. 只能使用系统预置的模板。",
      "B. 用户可以创建和保存自定义模板。",
      "C. 模板不支持变量。",
      "D. 模板只能用于文本生成。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "百炼支持灵活的自定义 Prompt 管理与变量插入",
    "type": "单选题",
    "id": "699"
  },
  {
    "question": "在 Python 中，lambda 表达式的作用是？",
    "options": [
      "A. 定义匿名函数。",
      "B. 定义类。",
      "C. 定义变量。",
      "D. 导入模块。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "lambda 是 Python 定义匿名函数的关键字。",
    "type": "单选题",
    "id": "700"
  },
  {
    "question": "以下哪个步骤可以提高 RAG 系统的抗干扰能力？",
    "options": [
      "A. 增加检索文档的数量。",
      "B. 使用 Query Rewrite（查询重写）优化用户输入。",
      "C. 降低 Embedding 模型的维度。",
      "D. 减少 Prompt 的长度。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "查询重写能修正用户输入的模糊、歧义或缺失，直接提升检索准确率与系统鲁棒性。",
    "type": "单选题",
    "id": "701"
  },
  {
    "question": "关于大模型的 “Zero-shot（零样本）” 能力，以下描述正确的是？",
    "options": [
      "A. 模型无法完成没有见过的任务。",
      "B. 模型可以在没有示例的情况下，仅凭指令完成任务。",
      "C. 模型需要大量样本才能完成任务。",
      "D. 只有经过微调的模型才有 Zero-shot 能力。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Zero-shot 是 LLM 的核心涌现能力之一，即“仅凭指令做事”。",
    "type": "单选题",
    "id": "702"
  },
  {
    "question": "在 LlamaIndex 中，Node Parser 的作用是？",
    "options": [
      "A. 将 Document 切分为更小的 Node。",
      "B. 解析 HTML 文档。",
      "C. 解析 JSON 文件。",
      "D. 将查询转换为向量。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Node Parser 是文档切片器，将 Document 粒度细化为 Node 粒度。",
    "type": "单选题",
    "id": "703"
  },
  {
    "question": "关于 “数据脱敏”，以下说法正确的是？",
    "options": [
      "A. 只需要对姓名进行脱敏。",
      "B. 脱敏是为了保护个人隐私和敏感信息。",
      "C. 脱敏后的数据无法用于模型训练。",
      "D. 只有金融行业需要数据脱敏。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "脱敏是普适性的数据安全措施，旨在平衡数据可用性与隐私保护。",
    "type": "单选题",
    "id": "704"
  },
  {
    "question": "在 Python 中，__init__ 方法的作用是？",
    "options": [
      "A. 类的构造函数，用于初始化对象。",
      "B. 类的析构函数，用于销毁对象。",
      "C. 定义类的静态方法。",
      "D. 定义类的私有方法。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "__init__ 是 Python 类的初始化方法。",
    "type": "单选题",
    "id": "705"
  },
  {
    "question": "在使用大模型 API 时，如何处理 API 限流（Rate Limit）？",
    "options": [
      "A. 立即重试。",
      "B. 增加并发数。",
      "C. 使用指数退避（Exponential Backoff）策略进行重试。",
      "D. 放弃请求。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "指数退避是处理分布式系统限流的标准且优雅的重试策略。",
    "type": "单选题",
    "id": "706"
  },
  {
    "question": "以下哪种方式可以优化 RAG 系统的检索速度？",
    "options": [
      "A. 使用更高维度的向量。",
      "B. 使用近似最近邻搜索（ANN）算法。",
      "C. 增加文档的数量。",
      "D. 每次都进行全量暴力搜索。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "ANN（如 HNSW、IVF）通过牺牲微小的精度换取检索速度的数量级提升，是向量检索\n的核心技术。",
    "type": "单选题",
    "id": "707"
  },
  {
    "question": "关于阿里云百炼平台的 “应用监控”，主要可以监控哪些指标？",
    "options": [
      "A. 模型的响应时间。",
      "B. 模型的 Token 消耗。",
      "C. 应用的 QPS（每秒请求数）。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "应用监控覆盖性能（延时、QPS）和成本（Token）等全维度指标。",
    "type": "单选题",
    "id": "708"
  },
  {
    "question": "在微调过程中，Train Loss 下降但 Validation Loss 上升，说明？",
    "options": [
      "A. 模型训练正常。",
      "B. 模型过拟合。",
      "C. 模型欠拟合。",
      "D. 学习率过大。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "这是过拟合的典型特征：在训练集表现优异但在验证集恶化。",
    "type": "单选题",
    "id": "709"
  },
  {
    "question": "以下哪个 Python 库常用于 Web 开发？",
    "options": [
      "A. NumPy",
      "B. Pandas",
      "C. Flask",
      "D. Matplotlib"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Flask 是 Python 轻量级 Web 框架。",
    "type": "单选题",
    "id": "710"
  },
  {
    "question": "关于 “Few-shot（少样本）” 提示技术，以下说法正确的是？",
    "options": [
      "A. 需要提供成千上万个样本。",
      "B. 在 Prompt 中提供少量（如 1-5 个）示例，帮助模型理解任务。",
      "C. 不需要任何示例。",
      "D. 只能用于分类任务。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Few-shot 通过少量示例（Demonstrations）激活模型的上下文学习能力（In-Context\nLearning）。",
    "type": "单选题",
    "id": "711"
  },
  {
    "question": "在 RAG 系统中，Keyword Search（关键词检索）的优势是？",
    "options": [
      "A. 理解语义。",
      "B. 精确匹配特定术语或名称。",
      "C. 处理长文本。",
      "D. 支持多语言。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "关键词检索（如 BM25）在精确匹配专有名词、特定代码等场景下优于向量检索。",
    "type": "单选题",
    "id": "712"
  },
  {
    "question": "关于大模型的 “参数量”，以下描述最准确的是？",
    "options": [
      "A. 参数量越大，模型一定越好。",
      "B. 参数量是指模型训练数据的数量。",
      "C. 参数量是模型中可学习权重的数量，通常与模型能力呈正相关。",
      "D. 参数量越小，推理速度越慢。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "参数量代表模型容量，通常越大能力越强（Scaling Law），但非绝对线性关系。",
    "type": "单选题",
    "id": "713"
  },
  {
    "question": "在使用 LlamaIndex 时，Index 结构的作用是？",
    "options": [
      "A. 存储原始文档。",
      "B. 组织和检索数据。",
      "C. 生成回答。",
      "D. 评估模型性能。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Index 是 LlamaIndex 的核心数据结构，负责高效组织数据以供检索。",
    "type": "单选题",
    "id": "714"
  },
  {
    "question": "以下哪种措施可以提高 Prompt 的安全性？",
    "options": [
      "A. 将 Prompt 公开。",
      "B. 对用户输入进行长度限制。",
      "C. 使用 delimiter（分隔符）防止 Prompt 注入。",
      "D. 不对用户输入进行任何处理。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "使用分隔符（如```）明确隔离系统指令与用户输入，是防御 Prompt Injection 的基\n础手段。",
    "type": "单选题",
    "id": "715"
  },
  {
    "question": "在 Python 中，*args 和 **kwargs 的作用是？",
    "options": [
      "A. 定义全局变量。",
      "B. 处理可变数量的参数。",
      "C. 导入模块。",
      "D. 定义类属性。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "*args 接收位置参数元组，**kwargs 接收关键字参数字典，用于实现变长参数函数。",
    "type": "单选题",
    "id": "716"
  },
  {
    "question": "在使用大模型 API 时，System Fingerprint 参数的作用是？",
    "options": [
      "A. 识别用户的设备指纹。",
      "B. 帮助追踪后端系统的配置变更，用于调试确定性问题。",
      "C. 加密 API 请求。",
      "D. 限制 API 调用频率。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "System Fingerprint 用于标识模型后端的具体版本/配置，辅助排查输出一致性问题。",
    "type": "单选题",
    "id": "717"
  },
  {
    "question": "以下哪种方式不适合用于优化 RAG 的生成效果？",
    "options": [
      "A. 优化 System Prompt。",
      "B. 提供更多相关的上下文。",
      "C. 减少上下文的数量，只保留最相关的一条。",
      "D. 随机删除一部分上下文。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "随机删除上下文会丢失信息，破坏生成质量，是完全错误的操作。",
    "type": "单选题",
    "id": "718"
  },
  {
    "question": "关于阿里云百炼平台的 “API Key”，以下说法正确的是？",
    "options": [
      "A. 可以分享给任何人。",
      "B. 是访问平台服务的凭证，应妥善保管，避免泄露。",
      "C. 永不过期。",
      "D. 只能创建一个。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "API Key 是鉴权核心，泄露会导致资损与安全风险。",
    "type": "单选题",
    "id": "719"
  },
  {
    "question": "在微调过程中，Batch Size（批次大小）过小会导致？",
    "options": [
      "A. 训练速度变快。",
      "B. 梯度估计不准确，训练震荡。",
      "C. 显存占用增加。",
      "D. 模型过拟合。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Batch Size 过小会导致梯度方向随机性大，难以稳定收敛。",
    "type": "单选题",
    "id": "720"
  },
  {
    "question": "以下哪个 Python 库常用于数据可视化？",
    "options": [
      "A. NumPy",
      "B. Pandas",
      "C. Matplotlib",
      "D. Requests"
    ],
    "answer": [
      "C"
    ],
    "analysis": "Matplotlib 是 Python 最基础的绘图库。",
    "type": "单选题",
    "id": "721"
  },
  {
    "question": "关于 “CoT（思维链）” 的局限性，以下说法正确的是？",
    "options": [
      "A. 适用于所有任务。",
      "B. 对于简单任务，可能会降低效率甚至导致错误。",
      "C. 不需要消耗额外的 Token。",
      "D. 只能在 GPT-4 上使用。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "CoT 会显著增加 Token 消耗，且在简单任务上可能因“过度思考”引入噪声。",
    "type": "单选题",
    "id": "722"
  },
  {
    "question": "在 RAG 系统中，Metadata Filtering（元数据过滤）的作用是？",
    "options": [
      "A. 过滤掉不相关的文档。",
      "B. 在检索前或检索后，根据元数据（如时间、作者、标签）筛选文档。",
      "C. 修改文档的元数据。",
      "D. 生成文档的摘要。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "元数据过滤能实现“带条件的精确检索”，大幅提升特定场景下的查准率。",
    "type": "单选题",
    "id": "723"
  },
  {
    "question": "关于大模型的 “Scaling Laws（缩放定律）”，以下描述最准确的是？",
    "options": [
      "A. 模型越大，训练越慢。",
      "B. 随着模型参数量、数据量和计算量的增加，模型性能会呈现可预测的提升。",
      "C. 模型性能与参数量无关。",
      "D. 数据量比参数量更重要。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Scaling Law 揭示了算力、数据、参数与性能之间的幂律关系。",
    "type": "单选题",
    "id": "724"
  },
  {
    "question": "在使用 LlamaIndex 时，Retriever 的作用是？",
    "options": [
      "A. 定义检索策略，从 Index 中获取相关 Node。",
      "B. 生成索引。",
      "C. 解析文档。",
      "D. 评估结果。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Retriever 封装了检索逻辑（如 Top-K、过滤条件等），是 RAG 获取信息的入口。",
    "type": "单选题",
    "id": "725"
  },
  {
    "question": "以下哪种方式可以减少大模型的幻觉？",
    "options": [
      "A. 提高 Temperature。",
      "B. 使用 RAG 技术，让模型基于检索到的事实回答。",
      "C. 减少 Prompt 的长度。",
      "D. 停止训练模型。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "RAG 通过外挂知识库限制模型“胡编乱造”，是当前解决幻觉最有效的主流方案。",
    "type": "单选题",
    "id": "726"
  },
  {
    "question": "在 Python 中，装饰器（Decorator）的作用是？",
    "options": [
      "A. 定义类。",
      "B. 修改函数或类的行为，而不改变其源代码。",
      "C. 导入模块。",
      "D. 处理异常。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "装饰器是 AOP（面向切面编程）在 Python 中的实现。",
    "type": "单选题",
    "id": "727"
  },
  {
    "question": "在使用大模型 API 时，Frequency Penalty 参数的作用是？",
    "options": [
      "A. 惩罚多次出现的 Token，降低其再次生成的概率，减少重复。",
      "B. 增加生成的长度。",
      "C. 提高生成的准确性。",
      "D. 增加重复内容的生成。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Frequency Penalty 依据 Token 出现频率进行惩罚，有效抑制复读机现象。",
    "type": "单选题",
    "id": "739"
  },
  {
    "question": "以下哪种方式适合用于 RAG 的结果评估？",
    "options": [
      "A. 仅凭感觉判断。",
      "B. 使用 RAGAS 等自动化评测框架。",
      "C. 只看检索到的文档数量。",
      "D. 不进行评估。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "自动化量化评估（如 RAGAS）是 RAG 迭代优化的科学依据。",
    "type": "单选题",
    "id": "740"
  },
  {
    "question": "关于阿里云百炼平台的 “Prompt 优化”，其功能是？",
    "options": [
      "A. 自动生成代码。",
      "B. 帮助用户优化 Prompt 的结构和表达，提升模型效果。",
      "C. 压缩 Prompt 长度。",
      "D. 加密 Prompt。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Prompt 优化工具利用 LLM 自身能力重写 Prompt，使其更符合模型指令遵循习惯。",
    "type": "单选题",
    "id": "741"
  },
  {
    "question": "在微调过程中，Gradient Accumulation（梯度累积）的作用是？",
    "options": [
      "A. 减少训练时间。",
      "B. 在显存受限的情况下，通过累积多个小批次的梯度来模拟大批次训练。",
      "C. 增加模型参数。",
      "D. 防止过拟合。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "梯度累积是显存不足时的经典妥协方案，以时间换空间。",
    "type": "单选题",
    "id": "742"
  },
  {
    "question": "以下哪个 Python 库常用于深度学习？",
    "options": [
      "A. PyTorch",
      "B. Flask",
      "C. Requests",
      "D. PyGame"
    ],
    "answer": [
      "A"
    ],
    "analysis": "PyTorch 是目前最流行的深度学习框架之一。",
    "type": "单选题",
    "id": "743"
  },
  {
    "question": "在 APIAssistantAgent 的 query 方法中，dashscope.Runs.wait 的作用是什么？\npython\nclass APIAssistantAgent(AgentModule):\ndef query(self, query: str):\n\"\"\"\nquery: string, the query string to the assistant. e.g. Who is the Jack Chou?\n\"\"\"\nmessage = dashscope.Messages.create(self.thread.id, content=query)\nmessage_run = dashscope.Runs.create(self.thread.id, assistant_id=self.assistant.id)\nrun_status = dashscope.Runs.wait(message_run.id, thread_id=self.thread.id)\nif run_status.required_action:\nself._forward_and_submit_outputs(run_status)\nrun_status = dashscope.Runs.wait(run_status.id, thread_id=self.thread.id)\nmsgs = dashscope.Messages.list(self.thread.id)\nanswer = json.loads(json.dumps(msgs, default=lambda o:\no.__dict__))['data'][0]['content'][0]['text']['value']\nreturn answer",
    "options": [
      "A. 返回请求的实时进度，对于调试非常有用",
      "B. 等待所有的辅助工具输出，确保信息的完整性",
      "C. 监听后台请求，并在用户的等待期间消耗资源",
      "D. 确保所有消息都已处理并存储好",
      "E. 阻塞当前线程，直到请求的响应准备好为止",
      "F. 提供异步呼叫的机制，以提升查询响应速度"
    ],
    "answer": [
      "B",
      "E"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "744"
  },
  {
    "question": "以下哪些选项属于流式输出相比于非流式输出的优势？",
    "options": [
      "A. 能够提升大模型回复的效果",
      "B. 能够给用户带来良好的阅读体验",
      "C. 能够加快大模型回复的速度",
      "D. 在网络连接时不会造成可能存在的超时错误"
    ],
    "answer": [
      "B",
      "D"
    ],
    "analysis": "流式输出的核心优势是 优化用户体验 和 提升网络稳定性，而非直接影响模型性能。适\n用于实时交互场景如聊天机器人、长文本生成，但需结合前端优化以最大化用户体验提升。",
    "type": "多选题",
    "id": "745"
  },
  {
    "question": "以下哪些选项是 abstract_generator 函数中提示词模板的关键组成部分？\npython\ndef abstract_generator(document):\nprompt_template=\"\"\"【角色背景】\n你是一个专业的审稿人，你将阅读文稿，并生成摘要\n【任务要求】\n你将看到一篇文章。请提取文章的主旨。\n【输出要求】\n请以 json 格式输出，不要输出其他内容\n如{\"abstract\":\"xxx\"}\n摘要本身的内容不超过 40个字\n【用户输入】\n以下是用户输入，请审阅：\n\"\"\"\nquery=prompt_template+document\nQ_S(system,query)",
    "options": [
      "A. 任务要求描述",
      "B. 角色背景设定",
      "C. 输出格式要求",
      "D. 错误处理机制",
      "E. 用户输入示例"
    ],
    "answer": [
      "A",
      "B",
      "C"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "746"
  },
  {
    "question": "以下选项中属于使用分隔符的主要目的有哪些？",
    "options": [
      "A. 规范化文档格式",
      "B. 明确提示词各要素之间的界限",
      "C. 使文档看起来更复杂",
      "D. 增加文字数量",
      "E. 随意分割文本",
      "F. 提高模型的运行速度"
    ],
    "answer": [
      "A",
      "B"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "747"
  },
  {
    "question": "在以下代码段中，哪些是设置模型训练参数的例子？",
    "options": [
      "A. learning_rate = 0.001",
      "B. model=\"qwen-7b - chat\"",
      "C. device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
      "D. optimizer = AdamW(model.parameters(), lr=learning_rate)",
      "E. num_epochs = 3",
      "F. batch_size = 64"
    ],
    "answer": [
      "A",
      "D",
      "E",
      "F"
    ],
    "analysis": "直接控制训练过程（如学习率、批次大小），可通过调整影响模型性能（如 epoch 数）",
    "type": "多选题",
    "id": "748"
  },
  {
    "question": "以下哪些场景适合使用流式对话 LLM_MODEL.stream_chat (messages)？",
    "options": [
      "A. 实时聊天机器人，需要立即响应用户输入。",
      "B. 需要对大模型的输出进行实时监控和干预的场景。",
      "C. 用户需要快速获得初步结果，后续可以继续补充信息完善结果。",
      "D. 只需要一次性返回完整结果的简单任务，例如翻译单个单词。",
      "E. 需要处理长文本输入的场景，可以逐步返回结果，避免超时。"
    ],
    "answer": [
      "A",
      "B",
      "C",
      "E"
    ],
    "analysis": "D 简单任务无实时交互需求，流式反而增加复杂度",
    "type": "多选题",
    "id": "749"
  },
  {
    "question": "以下哪些措施可以提高大模型在私域场景下的安全性？",
    "options": [
      "A. 对相关人员进行安全培训",
      "B. 建立完善的安全 incident 响应机制",
      "C. 使用开源的数据管理软件",
      "D. 将所有数据存储在云端",
      "E. 定期更新大模型和相关软件",
      "F. 对大模型进行持续的安全评估和测试"
    ],
    "answer": [
      "A",
      "B",
      "E",
      "F"
    ],
    "analysis": "核心措施：人员培训（A）+ 应急机制（B）+ 持续更新（E）+ 安全测试（F）\n需避免：盲目依赖开源（C）或云端（D），需结合业务需求定制方案",
    "type": "多选题",
    "id": "750"
  },
  {
    "question": "在监控大语言模型训练性能时，哪些指标是常用的？",
    "options": [
      "A. 训练时间",
      "B. 生成速度",
      "C. batch size",
      "D. 精准率",
      "E. 损失函数值",
      "F. 准确率"
    ],
    "answer": [
      "A",
      "B",
      "E"
    ],
    "analysis": "",
    "type": "多选题",
    "id": "751"
  },
  {
    "question": "你想使用 Qwen - Max 从一段冗长的课程文本中提炼出关键信息，用于创建 PPT 脚本。\n以下哪个提示词最合适？",
    "options": [
      "A. 用更少的字概括这段文字",
      "B. 缩短这段文字",
      "C. 从以下课程文本中提取关键信息，生成一个简洁的 PPT 脚本大纲，突出重点内容，并控制在 5 个要点以内。",
      "D. 把这段文字变成 PPT"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "752"
  },
  {
    "question": "在设定大语言模型的训练参数时，哪个参数可以影响模型每次更新时所考虑的数据量，并\n间接影响到模型收敛速度和内存使用？",
    "options": [
      "A. 学习率",
      "B. 正则化",
      "C. 批大小",
      "D. 动态学习率策略"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "753"
  },
  {
    "question": "StorageContext.from_defaults (persist_dir=PERSIST_DIR) 的作用是什么？",
    "options": [
      "A. 创建一个新的 StorageContext 对象，并使用默认配置，但指定持久化目录。",
      "B. 将 StorageContext 对象保存到 PERSIST_DIR。",
      "C. 从 PERSIST_DIR 加载 StorageContext 对象。",
      "D. 创建一个默认的 StorageContext 对象，并忽略 PERSIST_DIR。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "754"
  },
  {
    "question": "以下哪种方法不属于常见的文档切片方法？",
    "options": [
      "A. 按词性分割",
      "B. 按 token 长度分割",
      "C. 按语义分割",
      "D. 按字符分割"
    ],
    "answer": [
      "B"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "755"
  },
  {
    "question": "以下哪种方式不符合 Multi-Agent 的处理思想？",
    "options": [
      "A. 将文档的标题改写、表格单元格改写和语义分割都交给同一个大模型一次性完成。",
      "B. 使用 DashScopeParse 解析文档结构，再使用通义千问 API 润色文本。",
      "C. 使用规则引擎处理简单的文本格式转换，使用大模型处理复杂的语义理解任务。",
      "D. 根据不同的子任务需求，选择不同的模型类型和参数。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Multi-Agent 的核心原则,任务分解将复杂问题拆解为子任务。专业化分配为每个子任务\n选择最优工具（规则引擎、小模型、大模型等）,协同流程：通过管道（Pipeline）或消息传递\n整合结果。",
    "type": "单选题",
    "id": "756"
  },
  {
    "question": "以下哪种文档切片方法能够更好地保持句子的完整性？",
    "options": [
      "A. 基于语义的切片，通过 markdown 文档结构进行",
      "B. 基于句子的切片",
      "C. 随机切片",
      "D. 基于语义的切片，通过嵌入模型计算语义断点",
      "E. 基于字符切片",
      "F. 基于固定 token 长度切片"
    ],
    "answer": [
      "B"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "757"
  },
  {
    "question": "以下哪段代码实现了模型训练过程中的损失函数计算？",
    "options": [
      "A. for epoch in range(num_epochs):",
      "B. optimizer.zero_grad()",
      "C. with torch.no_grad(): correct +=(predicted ==labels).sum().item()",
      "D. loss =F.nll_loss(output,target,reduction='sum')"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "758"
  },
  {
    "question": "下面哪个 Python 库函数常用于计算 F1 分数？",
    "options": [
      "A. sklearn.metrics.recall_score",
      "B. sklearn.metrics.accuracy_score",
      "C. sklearn.metrics.f1_score",
      "D. sklearn.metrics.precision_score"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "759"
  },
  {
    "question": "以下哪个提示词要素用于约束大模型的应答风格，使其符合特定人群的阅读习惯？",
    "options": [
      "A. 角色（Role）",
      "B. 输出格式（Output Fomat）",
      "C. 上下文（Context）",
      "D. 受众（Audience）"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "760"
  },
  {
    "question": "以下哪种情况更适合使用代码解释器插件而不是直接使用大模型？",
    "options": [
      "A. 将一组文档按主题分类",
      "B. 分析一段文本的情感",
      "C. 从用户评论中提取关键信息",
      "D. 计算两组数据之间的皮尔逊相关系数"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "761"
  },
  {
    "question": "向量数据库的主要作用是什么？",
    "options": [
      "A. 存储和管理大量的关系型数据。",
      "B. 存储和管理大量的图像 。",
      "C. 存储和管理大量的向量数据，并提供高效的相似性检索。",
      "D. 存储和管理大量的文本数据，并提供全文检索功能。"
    ],
    "answer": [
      "C"
    ],
    "analysis": "向量数据库的核心价值在于高效处理向量相似性搜索，而非结构化数据或传统检索",
    "type": "单选题",
    "id": "762"
  },
  {
    "question": "以下哪个数据结构更适合用于实现关键词匹配，以提高匹配效率",
    "options": [
      "A. 栈",
      "B. 数组",
      "C. 链表",
      "D. 字典树"
    ],
    "answer": [
      "D"
    ],
    "analysis": "字典树：匹配关键词“cat”只需依次比较 c→a→t，路径唯一，数组/链表：需遍历所\n有关键词逐个比较",
    "type": "单选题",
    "id": "763"
  },
  {
    "question": "以下哪种方法最适合用于明确指定大模型输出的格式和类型？",
    "options": [
      "A. 仅使用上下文（Context）",
      "B. 仅使用角色（Role）",
      "C. 仅使用任务目标（Object）",
      "D. 结合输出格式（Output Format）和样例（Sample）"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "764"
  },
  {
    "question": "设计程序时，一般不会设计为调用一次大模型就处理完所有任务。下列关于如上说法的分\n析中，错误的是哪一项？",
    "options": [
      "A. 单个大模型无法处理多种格式的文件。",
      "B. 可以根据任务特点选择合适的模型和参数。",
      "C. 难以同时保证每项工作的质量。",
      "D. 可以分步优化，提高整体处理效率和成本。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "765"
  },
  {
    "question": "通过 LlamaIndex 创建 RAG 应用时，一份知识文件是如何传入 RAG 应用的，请选择顺序：",
    "options": [
      "A. Node 对象 - query_engine-Document 对象 - index",
      "B. Document 对象 - Node 对象 - index-query_engine",
      "C. Node 对象 - Document 对象 - index-query_engine",
      "D. Document 对象 - index-Node 对象 - query_engine"
    ],
    "answer": [
      "B"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "766"
  },
  {
    "question": "如果要修改摘要生成函数，使其生成的摘要不超过 80 个字，应该如何修改？",
    "options": [
      "A. 假设生成结果为 query，生成结果后添加 query=query [:80]。",
      "B. 以上修改方法均不正确。",
      "C. 在提示词部分明确写出摘要本身的内容不超过 80 个字。",
      "D. 假设输入的文档为 document，在函数开头添加"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "767"
  },
  {
    "question": "关于输入数据的描述，以下哪项是正确的？",
    "options": [
      "A. 输入数据应当明确具体含义及其用途",
      "B. 输入数据不影响模型输出格式",
      "C. 输入数据是可选的",
      "D. 输入数据仅用于生成样例",
      "E. 输入数据无需说明",
      "F. 输入数据可以通过模糊的引导词来定义其作用"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "768"
  },
  {
    "question": "以下关于基于规则的文本合规检查方法的描述，哪一项是不正确的？",
    "options": [
      "A. 对于特定高风险场景效果显著。",
      "B. 需要维护一个规则库，例如包含正则表达式、敏感词或模式。",
      "C. 规则更新可能不及时，人工维护成本较高。",
      "D. 具有很强的数据泛化能力，可以有效识别新的变种。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "769"
  },
  {
    "question": "用户向基于 RAG 的智能答疑机器人提交了一张包含敏感信息的图片进行咨询。根据最佳\n实践，最早应该在哪个阶段进行内容安全合规检查以阻止敏感信息泄露？",
    "options": [
      "A. 机器人根据用户图片检索时",
      "B. 机器人响应返回答案之后检查",
      "C. 在机器人处理图片之前检查",
      "D. 将答案返回给用户之前检查"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "770"
  },
  {
    "question": "在提示词构建中，哪个要素用于指定大模型的回应风格或语气？",
    "options": [
      "A. 输出格式",
      "B. 样例",
      "C. 任务目标",
      "D. 上下文",
      "E. 输入数据",
      "F. 角色"
    ],
    "answer": [
      "F"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "771"
  },
  {
    "question": "如何获取大模型返回信息的文本内容？\npython\nimport osfrom openai import OpenAI\nclient=OpenAI(\napi_key=os.getenv(\"DASHSCOPE_API_KEY\"),\nbase_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\")\ncompletion=client.chat.completions.create(\nmodel=\"qwen-max\",\nmessages=[{\"role\":\"user\",\"content\":\" 你 是\n谁?\"}])print(completion.choices[0].message.content)",
    "options": [
      "A. completion.choices[0]",
      "B. completion.message.content",
      "C. completion.choices[0].message.content",
      "D. completion.choices.content"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "772"
  },
  {
    "question": "以下哪个用户查询语句无法有效地指导大模型进行文本摘要？",
    "options": [
      "A. 请总结以下文章的主要内容：...",
      "B. 提取以下文本的关键词：...",
      "C. 请翻译以下文章：...",
      "D. 将以下文章压缩到 100 字以内：...",
      "E. 用一句话概括以下文字："
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "773"
  },
  {
    "question": "在调用百炼大模型接口时，如何指定用户的输入内容？",
    "options": [
      "A. 将用户输入内容作为'messages'列表中字典的'content'字段的值传入",
      "B. 将用户输入内容作为 model参数的值传入",
      "C. 将用户输入内容作为 api_key参数的值传入",
      "D. 将用户输入内容作为 base_url 参数的值传入"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "774"
  },
  {
    "question": "通过 LlamaIndex 创建 RAG 应用时，node_postprocessors 的作用是？",
    "options": [
      "A. 设置召回文本段个数",
      "B. 修改 prompt 模板",
      "C. 开启句子窗口检索",
      "D. 进行后处理，如相似度阈值、rerank 等"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "775"
  },
  {
    "question": "在检测文档内容中是否存在营销表达时，下列哪种方法可以更全面地识别问题？",
    "options": [
      "A. 识别有内容错误的部分",
      "B. 逐条单独识别营销词汇",
      "C. 一次性生成所有类型的识别结果",
      "D. 让大模型自动修改内容"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "776"
  },
  {
    "question": "在使用 Assistant API 时，如何验证 API 请求是否成功？",
    "options": [
      "A. if response.status_code ==HTTPStatus.CREATED:",
      "B. if response.status_code ==HTTPStatus.BAD_REQUEST:",
      "C. if response.status_code ==HTTPStatus.OK:",
      "D. if response.status_code==HTTPStatus.NOT_FOUND:"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "777"
  },
  {
    "question": "在大语言模型微调训练中，哪一步骤涉及到计算损失函数关于模型参数的梯度？",
    "options": [
      "A. 正向传播",
      "B. 批标准化",
      "C. 优化算法选择",
      "D. 反向传播"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "778"
  },
  {
    "question": "API AssistantAgent 示例代码 verify_status_code 函数的作用是什么？\npython\ndef verify_status_code(res):\nif res.status_code !=HTTPStatus.OK:\nprint(\"Failed:\")\nprint(res)\nsys.exit(res.status_code)",
    "options": [
      "A. 验证 function call 的参数是否正确",
      "B. 验证用户输入的 query 是否合法",
      "C. 验证 Assistant 是否成功创建",
      "D. 验证 Thread 是否成功创建",
      "E. 验证模型返回的答案是否符合预期",
      "F. 验证 API 调用的返回状态码是否为 200"
    ],
    "answer": [
      "F"
    ],
    "analysis": "示例代码中的 verify_status_code 函数通过检查响应对象的 status_code 属性，判断\nAPI 调用是否成功（HTTP 状态码 200 表示成功）。若状态码不为 200，则打印错误信息并终止\n程序",
    "type": "单选题",
    "id": "779"
  },
  {
    "question": "API AssistantAgent 示例代码_forward_and_submit_outputs函数的核心功能是什么？\npython\ndef _forward_and_submit_outputs(self,run_status):\n\"get the function name,run and return the function output to the server\"\nfunc_obj=run_status.required_action.submit_tool_outputs.tool_calls[0].function\nfunc_name =func_obj.name\narguments =json.loads(func_obj.arguments)\ntool_outputs=[\n{\n'tool_call_id':\nrun_status.required_action.submit_tool_outputs.tool_calls[0].id,\n'output':json.dumps(self.funcs[func_name](**arguments))\n}\n]\nrun_status =dashscope.Runs.submit_tool_outputs(run_status.id,\nthread_id=self.thread.id,\ntool_outputs=tool_outputs)\nreturn",
    "options": [
      "A. 获取 Assistant 的回复",
      "B. 创建新的 Assistant",
      "C. 创建新的 Thread",
      "D. 执行 function call 并将结果提交给服务器",
      "E. 等待 Run 完成",
      "F. 向 Assistant 提交用户 query"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "780"
  },
  {
    "question": "如何从百炼大模型的接口返回结果中获取模型生成的文本？",
    "options": [
      "A. python pythonprint(completion.message.content)",
      "B. python pythonprint(completion.choices[0].message)",
      "C. python pythonprint(completion.choices.message.content)",
      "D. python pythonprint(completion.choices[0].message.content)"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "781"
  },
  {
    "question": "大语言模型预训练与微调之间的关系是什么？",
    "options": [
      "A. 微调发生在预训练之前，用于准备数据",
      "B. 预训练和微调是相互独立的过程",
      "C. 微调是对预训练模型的初次训练",
      "D. 微调是在预训练模型基础上进行的调整优化"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "782"
  },
  {
    "question": "以下哪个分隔符形式不常用于提示词中？",
    "options": [
      "A. plaintext <example>...</example>",
      "B. plaintext ... &&& Part 1 &&& Part 2",
      "C. plaintext Section 1 Section 2",
      "D. plaintext -- ##Title Content"
    ],
    "answer": [
      "C"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "783"
  },
  {
    "question": "下列代码片段的作用是？\npython\nfrom keras.preprocessing.sequence import pad_sequences\npadded_seqs=pad_sequences(sequences,maxlen=max_len,padding='post',truncating='post\n')",
    "options": [
      "A. 序列填充到固定长度",
      "B. 文本摘要生成",
      "C. 特征缩放",
      "D. 文本向量化"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "784"
  },
  {
    "question": "作为应用开发者，如果想要让大模型避免回答与个人隐私相关的问题，最推荐在哪个角色\n中设置相应的限制？",
    "options": [
      "A. user",
      "B. assistant",
      "C. 任何角色都可以",
      "D. system"
    ],
    "answer": [
      "D"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "785"
  },
  {
    "question": "以下哪个选项最适合作为系统角色提示词，用于构建一个可以进行代码审查的 AI 助手？",
    "options": [
      "A. {\"role\":\"system\",\"content\":\"你是一个资深代码审查专家，专注于发现代码中的潜在问题， 例如 bug、性能瓶颈和代码风格问题。请提供详细的修改建议和解释。\"}",
      "B. {\"role\":\"user\",\"content\":\"这是我的代码，请帮我审查。\"}",
      "C. {\"role\":\"assistant\",\"content\":\"请提交需要审查的代码。\"}",
      "D. {\"role\":\"system\",\"content\":\"你是一个初级程序员，正在学习代码审查。\"}"
    ],
    "answer": [
      "A"
    ],
    "analysis": "",
    "type": "单选题",
    "id": "786"
  },
  {
    "question": "你希望对于同一个提示词，让大模型每次都尽最大可能返回相同结果，可以调整哪个参数？",
    "options": [
      "A. stream",
      "B. max_token",
      "C. api_key",
      "D. seed"
    ],
    "answer": [
      "D"
    ],
    "analysis": "A （stream） 主要用于控制大模型是否以流式传输的方式返回结果 ，也就是能否边生\n成内容边返回给用户，和让模型对于同一提示返回相同结果并无关联。B （max_token） 是用\n来限定模型生成文本时的最大 token 数量，主要影响生成文本的长度，而非生成结果的一致\n性 。C（api_key） 是应用程序访问大模型 API 的密钥，起到身份验证和授权访问的作用 ，\n和生成结果是否相同没有直接联系。D （seed） 在大模型相关操作中，seed（种子）参数就像\n一个随机数生成器的起始值。当设置固定的 seed 值时，模型的随机生成过程就会被“锁定”\n在同一条路径上，从而让模型对于同一个提示词，每次都尽最大可能返回相同的结果，所以\nD 选项是正确答案。",
    "type": "单选题",
    "id": "787"
  },
  {
    "question": "关于 Assistant API，以下说法正确的是？",
    "options": [
      "A. Thread 代表一个对话线程，可以包含多条 Message。",
      "B. Assistant 必须绑定一个 Knowledge Base。",
      "C. Run 对象一旦创建，就无法取消。",
      "D. 只能使用 GPT-4 模型。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Thread 是 Assistant API 中管理对话上下文的核心容器，支持多轮交互。",
    "type": "单选题",
    "id": "788"
  },
  {
    "question": "在 Python 中，如何定义一个装饰器？",
    "options": [
      "A. 使用 @decorator_name 语法。",
      "B. 使用 #decorator_name 语法。",
      "C. 使用 $decorator_name 语法。",
      "D. 使用 %decorator_name 语法。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "@ 是 Python 装饰器的语法糖。",
    "type": "单选题",
    "id": "789"
  },
  {
    "question": "关于 RAG 中的 “Rewrite-Retrieve-Read” 框架，以下描述正确的是？",
    "options": [
      "A. 先检索，再重写问题，最后阅读。",
      "B. 先重写问题，再检索，最后阅读生成。",
      "C. 先阅读生成，再检索，最后重写。",
      "D. 不需要检索。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "这是经典的高级 RAG 模式：通过 Rewrite 优化 Query，提升 Retrieve 质量，最终由\nRead 生成答案。",
    "type": "单选题",
    "id": "790"
  },
  {
    "question": "以下哪个工具可以用于向量数据库的可视化管理？",
    "options": [
      "A. Attu (for Milvus)",
      "B. phpMyAdmin",
      "C. Redis Desktop Manager",
      "D. MongoDB Compass"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Attu 是 Milvus 官方提供的向量数据库可视化管理工具。",
    "type": "单选题",
    "id": "791"
  },
  {
    "question": "在使用大模型进行情感分析时，输出结果通常是？",
    "options": [
      "A. 一段新的文本。",
      "B. 情感标签（如正面、负面、中性）或分数。",
      "C. 图像。",
      "D. 音频。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "情感分析属于分类或回归任务，输出标签或置信度分数。",
    "type": "单选题",
    "id": "792"
  },
  {
    "question": "关于 “Prompt Chaining（提示词链）”，以下说法正确的是？",
    "options": [
      "A. 将多个 Prompt 串联起来，前一个的输出作为后一个的输入。",
      "B. 同时发送多个 Prompt。",
      "C. 随机选择一个 Prompt。",
      "D. 加密 Prompt。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Prompt Chaining 通过分解复杂任务为多个子步骤（链式调用）来提升最终效果。",
    "type": "单选题",
    "id": "793"
  },
  {
    "question": "在 RAG 系统中，Document Loader 的作用是？",
    "options": [
      "A. 加载并解析各种格式的文档（PDF, HTML, TXT 等）。",
      "B. 生成向量。",
      "C. 存储向量。",
      "D. 生成答案。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Document Loader 是 ETL 流程的第一步，负责异构数据源的标准化接入。",
    "type": "单选题",
    "id": "794"
  },
  {
    "question": "关于 “Constitutional AI（宪法 AI）”，以下描述正确的是？",
    "options": [
      "A. 用 AI 来制定宪法。",
      "B. 通过一组预定义的原则（宪法）来指导和约束 AI 的行为，使其符合人类价值观。",
      "C. 只能在美国使用。",
      "D. 是一种法律文件。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Constitutional AI（由 Anthropic 提出）旨在通过“AI 反馈 AI（RLAIF）”实现价\n值观对齐。",
    "type": "单选题",
    "id": "795"
  },
  {
    "question": "在 Python 中，yield 关键字的作用是？",
    "options": [
      "A. 结束函数执行。",
      "B. 定义生成器函数，按需返回数据。",
      "C. 抛出异常。",
      "D. 声明全局变量。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "yield 将函数转换为生成器（Generator），支持惰性求值。",
    "type": "单选题",
    "id": "796"
  },
  {
    "question": "以下哪种方式可以提高 RAG 系统对多跳问题（Multi-hop Question）的回答能力？",
    "options": [
      "A. 增加文档数量。",
      "B. 使用思维链（CoT）和多步检索（Multi-step Retrieval）。",
      "C. 提高 Temperature。",
      "D. 减少 Top-K。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "多跳问题需要跨文档推理，CoT + 多步检索是解决此类问题的标准范式。",
    "type": "单选题",
    "id": "797"
  },
  {
    "question": "关于阿里云百炼平台的 “模型调优”，支持哪种微调方式？",
    "options": [
      "A. SFT（监督微调）。",
      "B. RLHF（人类反馈强化学习）。",
      "C. 预训练。",
      "D. 以上都支持。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "目前百炼平台主要通过 SFT（高效微调）赋能企业定制化模型。",
    "type": "单选题",
    "id": "798"
  },
  {
    "question": "在微调过程中，Checkpoint（检查点）的作用是？",
    "options": [
      "A. 检查数据质量。",
      "B. 定期保存模型权重，防止训练意外中断后需要重头开始，并用于选择最佳模型。",
      "C. 检查代码错误。",
      "D. 检查显存占用。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Checkpoint 是断点续训和模型优选的必要机制。",
    "type": "单选题",
    "id": "799"
  },
  {
    "question": "以下哪个 Python 库常用于自然语言处理（NLP）？",
    "options": [
      "A. NLTK",
      "B. Pillow",
      "C. SQLAlchemy",
      "D. PyTest"
    ],
    "answer": [
      "A"
    ],
    "analysis": "NLTK 是 Python 老牌 NLP 库（Pillow 处理图像，SQLAlchemy 处理数据库，PyTest\n测试）。",
    "type": "单选题",
    "id": "800"
  },
  {
    "question": "关于 “Tree of Thoughts（思维树）” 提示技术，以下说法正确的是？",
    "options": [
      "A. 是 CoT 的泛化形式，允许模型在推理过程中探索多种可能性，并进行回溯。",
      "B. 只能生成树形结构的文本。",
      "C. 计算成本很低。",
      "D. 不需要任何算法支持。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "ToT 将 LLM 推理过程建模为树搜索（如 BFS/DFS），显著提升复杂规划能力。",
    "type": "单选题",
    "id": "801"
  },
  {
    "question": "在 RAG 系统中，Embedding 模型的选择主要取决于？",
    "options": [
      "A. 模型的参数量。",
      "B. 语言支持、语义表达能力和向量维度。",
      "C. 模型的训练时间。",
      "D. 模型的名字。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Embedding 选型核心指标：多语言支持（C-MTEB 排名）、语义表征能力及维度适配\n性。",
    "type": "单选题",
    "id": "802"
  },
  {
    "question": "关于大模型的 “Tokenizer（分词器）”，以下描述最准确的是？",
    "options": [
      "A. 将文本转换为 Token 序列。",
      "B. 将 Token 序列转换为文本。",
      "C. 负责文本清洗。",
      "D. A 和 B。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "Tokenizer 包含 Encode（文本转 Token）和 Decode（Token 转文本）双向过程。",
    "type": "单选题",
    "id": "803"
  },
  {
    "question": "在使用 LlamaIndex 时，Query Engine 的作用是？",
    "options": [
      "A. 端到端的查询接口，接收用户查询并返回结果。",
      "B. 仅负责检索。",
      "C. 仅负责生成。",
      "D. 负责解析查询。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Query Engine 封装了 RAG 的全流程（Retrieval + Synthesis），对上层提供统一接口。",
    "type": "单选题",
    "id": "804"
  },
  {
    "question": "以下哪种攻击针对的是 RAG 系统的知识库？",
    "options": [
      "A. Prompt Injection",
      "B. Data Poisoning（数据投毒）",
      "C. DDoS",
      "D. Model Inversion"
    ],
    "answer": [
      "B"
    ],
    "analysis": "在 RAG 知识库中注入恶意文档（投毒），可诱导模型生成错误或有害信息。",
    "type": "单选题",
    "id": "805"
  },
  {
    "question": "在 Python 中，super() 函数的作用是？",
    "options": [
      "A. 调用父类的方法。",
      "B. 定义超级类。",
      "C. 增加权限。",
      "D. 终止程序。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "super() 用于在子类中调用父类（超类）的被覆盖方法。",
    "type": "单选题",
    "id": "806"
  },
  {
    "question": "在使用大模型 API 时，Top-k 参数的作用是？",
    "options": [
      "A. 仅从概率最高的 k 个 Token 中进行采样。",
      "B. 限制生成的长度。",
      "C. 提高生成的随机性。",
      "D. 降低生成的重复率。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Top-k 采样策略：截断概率尾部，保留头部 k 个候选词。",
    "type": "单选题",
    "id": "807"
  },
  {
    "question": "以下哪种方式可以提高 RAG 系统的查准率（Precision）？",
    "options": [
      "A. 增加 Top-K。",
      "B. 使用 Re-ranking。",
      "C. 使用更小的 Chunk Size。",
      "D. 降低 Similarity Threshold。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "Re-ranking 专门用于剔除 Top-K 中的“伪相关”文档，大幅提升 Precision。",
    "type": "单选题",
    "id": "808"
  },
  {
    "question": "关于阿里云百炼平台的 “数据管理”，支持哪些数据操作？",
    "options": [
      "A. 数据上传。",
      "B. 数据切片。",
      "C. 数据清洗。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "百炼提供全链路数据处理能力。",
    "type": "单选题",
    "id": "809"
  },
  {
    "question": "在微调过程中，Loss 不下降反而上升，可能是因为？",
    "options": [
      "A. 学习率过大。",
      "B. 数据集太小。",
      "C. 模型参数太多。",
      "D. 训练轮数不够。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Loss 发散（不降反升）最常见原因是学习率设置过大，导致梯度爆炸或跳出极小值域。",
    "type": "单选题",
    "id": "810"
  },
  {
    "question": "以下哪个 Python 库常用于异步编程？",
    "options": [
      "A. asyncio",
      "B. time",
      "C. datetime",
      "D. math"
    ],
    "answer": [
      "A"
    ],
    "analysis": "asyncio 是 Python 标准异步 I/O 库。",
    "type": "单选题",
    "id": "811"
  },
  {
    "question": "关于 “Least-to-Most Prompting” 技术，以下说法正确的是？",
    "options": [
      "A. 将复杂问题分解为子问题，先解决简单子问题，再利用其答案解决复杂问题。",
      "B. 从最难的问题开始解决。",
      "C. 不需要分解问题。",
      "D. 只能用于数学证明。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Least-to-Most 策略：化整为零，由易到难，逐步攻克。",
    "type": "单选题",
    "id": "812"
  },
  {
    "question": "在 RAG 系统中，GraphRAG 的优势是？",
    "options": [
      "A. 利用知识图谱捕捉实体间的复杂关系，提升对全局性、推理型问题的回答能力。",
      "B. 速度最快。",
      "C. 不需要 LLM。",
      "D. 存储空间最小。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "GraphRAG 弥补了传统 RAG 在跨文档关联和全局摘要能力上的短板。",
    "type": "单选题",
    "id": "813"
  },
  {
    "question": "关于大模型的 “Fine-tuning” 和 “RAG” 的区别，以下描述最准确的是？",
    "options": [
      "A. Fine-tuning 改变模型参数，注入内隐知识；RAG 不改变参数，外挂外显知识。",
      "B. Fine-tuning 成本低，RAG 成本高。",
      "C. Fine-tuning 实时性好，RAG 实时性差。",
      "D. 两者没有区别。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "这是微调与 RAG 的本质区别：内隐记忆（参数） vs 外显记忆（检索）。",
    "type": "单选题",
    "id": "814"
  },
  {
    "question": "在使用 LlamaIndex 时，Chat Engine 的作用是？",
    "options": [
      "A. 支持多轮对话模式的 RAG。",
      "B. 仅支持单轮问答。",
      "C. 用于生成代码。",
      "D. 用于图像识别。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Chat Engine 在 Query Engine 基础上增加了 Memory 管理，支持上下文对话。",
    "type": "单选题",
    "id": "815"
  },
  {
    "question": "以下哪种措施可以防止大模型输出有害内容？",
    "options": [
      "A. 使用内容安全过滤器（Content Safety Filter）。",
      "B. 提高 Temperature。",
      "C. 增加 Max Tokens。",
      "D. 使用更小的模型。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "安全过滤器（如阿里云内容安全服务）是拦截有害输出的最后一道防线。",
    "type": "单选题",
    "id": "816"
  },
  {
    "question": "在 Python 中，如何进行列表推导式（List Comprehension）？",
    "options": [
      "A. [x for x in iterable]",
      "B. list(x in iterable)",
      "C. for x in iterable: list.append(x)",
      "D. map(x, iterable)"
    ],
    "answer": [
      "A"
    ],
    "analysis": "[expression for item in iterable] 是 Python 特有的优雅列表构建语法。",
    "type": "单选题",
    "id": "817"
  },
  {
    "question": "在使用大模型 API 时，Seed 参数的作用是？",
    "options": [
      "A. 提高生成的确定性，便于复现结果。",
      "B. 增加随机性。",
      "C. 加密请求。",
      "D. 压缩数据。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "固定 Seed 可使具有随机性的模型在相同输入下产生（尽可能）一致的输出。",
    "type": "单选题",
    "id": "818"
  },
  {
    "question": "以下哪种方式可以优化 RAG 系统的召回率（Recall）？",
    "options": [
      "A. 增加 Top-K。",
      "B. 使用 Query Expansion（查询扩展）。",
      "C. 使用 HyDE（假设文档嵌入）。",
      "D. 以上都是。"
    ],
    "answer": [
      "D"
    ],
    "analysis": "A 扩大范围，B/C 丰富语义，均能有效提升 Recall。",
    "type": "单选题",
    "id": "819"
  },
  {
    "question": "关于阿里云百炼平台的 “模型对比”，其作用是？",
    "options": [
      "A. 比较不同模型在同一 Prompt 下的输出效果。",
      "B. 比较不同服务器的价格。",
      "C. 比较不同数据库的性能。",
      "D. 比较不同用户的权限。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "模型对比（Arena）帮助开发者直观选型。",
    "type": "单选题",
    "id": "820"
  },
  {
    "question": "在微调过程中，Optimizer（优化器）的作用是？",
    "options": [
      "A. 计算损失。",
      "B. 根据梯度更新模型参数，以最小化损失。",
      "C. 加载数据。",
      "D. 保存模型。"
    ],
    "answer": [
      "B"
    ],
    "analysis": "优化器（如 AdamW）负责执行参数更新的具体算法逻辑。",
    "type": "单选题",
    "id": "821"
  },
  {
    "question": "以下哪个 Python 库常用于处理 PDF 文件？",
    "options": [
      "A. PyPDF2",
      "B. NumPy",
      "C. Pandas",
      "D. Flask"
    ],
    "answer": [
      "A"
    ],
    "analysis": "PyPDF2（或 pypdf）是处理 PDF 的标准库。",
    "type": "单选题",
    "id": "822"
  },
  {
    "question": "关于 “ReAct” 提示框架，以下说法正确的是？",
    "options": [
      "A. 结合了 Reasoning（推理）和 Acting（行动）。",
      "B. 只需要推理，不需要行动。",
      "C. 只需要行动，不需要推理。",
      "D. 是一种情感分析技术。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "ReAct = Thought + Action + Observation，是 Agent 实现自主任务规划的基础范式。",
    "type": "单选题",
    "id": "823"
  },
  {
    "question": "在 RAG 系统中，Chunk Size（切片大小）过大会导致？",
    "options": [
      "A. 包含过多无关信息，干扰检索和生成（噪声大）。",
      "B. 语义截断。",
      "C. 索引过大。",
      "D. 检索速度变慢。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "切片过大 = 粒度粗 = 噪声多（Recall 可能高但 Precision 低）。",
    "type": "单选题",
    "id": "824"
  },
  {
    "question": "关于大模型的 “RLHF（人类反馈强化学习）”，以下描述最准确的是？",
    "options": [
      "A. 使用人类反馈来对齐模型行为，使其更符合人类价值观（有用、诚实、无害）。",
      "B. 不需要人类参与。",
      "C. 是一种无监督学习。",
      "D. 只能用于游戏 AI。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "RLHF 是 ChatGPT 等现代 LLM 能够听懂指令并安全输出的关键技术。",
    "type": "单选题",
    "id": "825"
  },
  {
    "question": "在使用 LlamaIndex 时，Data Connector 的作用是？",
    "options": [
      "A. 连接外部数据源（如 Notion, Slack, SQL 数据库）。",
      "B. 连接显示器。",
      "C. 连接打印机。",
      "D. 连接鼠标。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Data Connector（如 LlamaHub 中的插件）负责从各种 SaaS/DB 抽取数据。",
    "type": "单选题",
    "id": "826"
  },
  {
    "question": "以下哪种方式可以防止大模型泄露训练数据中的隐私？",
    "options": [
      "A. 差分隐私（Differential Privacy）。",
      "B. 公开所有训练数据。",
      "C. 不进行任何处理。",
      "D. 使用更大的模型。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "差分隐私通过引入噪声，在统计学上保证单个样本无法被反向推导。",
    "type": "单选题",
    "id": "827"
  },
  {
    "question": "在 Python 中，assert 语句的作用是？",
    "options": [
      "A. 断言条件为真，否则抛出 AssertionError。",
      "B. 定义函数。",
      "C. 循环。",
      "D. 打印输出。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "assert 用于调试时的条件检查。",
    "type": "单选题",
    "id": "828"
  },
  {
    "question": "在使用大模型 API 时，Stop Sequence 参数的作用是？",
    "options": [
      "A. 指定生成的停止词，遇到该词即停止生成。",
      "B. 停止 API 调用。",
      "C. 暂停模型。",
      "D. 停止计费。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Stop Sequence 允许开发者自定义生成的终止条件（如遇到“END”停止）。",
    "type": "单选题",
    "id": "829"
  },
  {
    "question": "以下哪种方式可以优化 RAG 系统的索引构建速度？",
    "options": [
      "A. 并行处理文档。",
      "B. 串行处理文档。",
      "C. 使用 CPU 而不是 GPU。",
      "D. 增加文档的大小。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "并行化（多线程/多进程）是加速 ETL 和 Embedding 的最直接手段。",
    "type": "单选题",
    "id": "830"
  },
  {
    "question": "关于阿里云百炼平台的 “自动评估”，以下说法正确的是？",
    "options": [
      "A. 使用大模型作为裁判（LLM-as-a-Judge）进行打分。",
      "B. 需要人工逐条打分。",
      "C. 只能评估准确率。",
      "D. 不支持自定义评估指标。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "百炼集成权威评测集，利用强模型（如 Qwen-Max）对弱模型输出进行自动化打分。",
    "type": "单选题",
    "id": "831"
  },
  {
    "question": "在微调过程中，Scheduler（学习率调度器）的作用是？",
    "options": [
      "A. 动态调整学习率（如 Warmup, Cosine Decay）。",
      "B. 固定学习率。",
      "C. 调整 Batch Size。",
      "D. 调整模型结构。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Scheduler 通过动态调整 LR（先升后降）优化收敛过程。",
    "type": "单选题",
    "id": "832"
  },
  {
    "question": "以下哪个 Python 库常用于图像处理？",
    "options": [
      "A. Pillow (PIL)",
      "B. Requests",
      "C. Pandas",
      "D. SQLAlchemy"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Pillow 是 Python 图像处理事实标准库。",
    "type": "单选题",
    "id": "833"
  },
  {
    "question": "关于 “Directional Stimulus Prompting” 技术，以下说法正确的是？",
    "options": [
      "A. 使用一个小的策略模型生成 “提示（Hint）” 或 “关键词”，引导大模型生成目标输出。",
      "B. 随机生成提示。",
      "C. 不需要任何提示。",
      "D. 只能用于摘要任务。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Directional Stimulus 通过引入额外引导信息（Hint）来定向控制生成内容。",
    "type": "单选题",
    "id": "834"
  },
  {
    "question": "在 RAG 系统中，Parent Document Retriever 的作用是？",
    "options": [
      "A. 检索小切片，返回其对应的大切片（父文档）给 LLM，兼顾检索精度和上下文完整性。",
      "B. 只检索父文档。",
      "C. 只检索子文档。",
      "D. 不进行检索。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "这是解决“切片粒度困境”的高级策略：小粒度匹配，大粒度生成。",
    "type": "单选题",
    "id": "835"
  },
  {
    "question": "关于大模型的 “Catastrophic Forgetting（灾难性遗忘）”，以下描述最准确的是？",
    "options": [
      "A. 在学习新任务时，遗忘了旧任务的知识。",
      "B. 模型无法学习新知识。",
      "C. 模型崩溃。",
      "D. 模型参数丢失。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "灾难性遗忘是全量微调的常见副作用。",
    "type": "单选题",
    "id": "836"
  },
  {
    "question": "在使用 LlamaIndex 时，Callback Manager 的作用是？",
    "options": [
      "A. 追踪和记录系统运行时的事件（如 Token 使用、延迟、检索结果），用于调试和监控。",
      "B. 管理回调函数。",
      "C. 没有任何作用。",
      "D. 用于用户登录。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "Callback Manager 是可观测性（Observability）的基础。",
    "type": "单选题",
    "id": "837"
  },
  {
    "question": "以下哪种措施可以提高大模型应用的鲁棒性？",
    "options": [
      "A. 增加异常处理和降级机制。",
      "B. 减少测试用例。",
      "C. 使用单一模型。",
      "D. 不进行监控。"
    ],
    "answer": [
      "A"
    ],
    "analysis": "鲁棒性设计必须包含容错、重试及兜底策略（Fallbacks）。",
    "type": "单选题",
    "id": "838"
  }
]